foreign
and welcome to this amazing artificial
intelligence crash course by simply Love
Before We Begin if you enjoy watching
these type of videos and find them
interesting subscribe to our YouTube
channel as we bring you the best videos
daily also hit the Bell icon to never
miss any update from Simply enough so
let's get started
we will be briefing you with a detailed
introduction to artificial intelligence
that covers the data sources and the
types of AI after that we will see the
AI engineer roadmap and after that we
will see the top skills required to
become an AI engineer up ahead we will
walk you through some amazing Concepts
like supervised versus unsupervised
versus reinforcement learning
moving forward we will see linear
regression and many more after that we
will see the top 10 AI projects ideas
after that we will see the top 10 AI
companies and at the last we will see
the career opportunities in AI moving
forward we will cover Amazing Project in
this crash course like movie
recommendation systems speaking of
interviews we have covered you along
with the most frequently Asked
artificial intelligence interview
question to help you correct the
toughest interviews before we move on to
the what AI is if you are an aspiring
AIML engineer then there is no better
time to train yourself in the exciting
field of AI if you are looking for a
course that covers everything from
fundamental to Advanced Techniques then
accelerate your career in Ai and ml with
our comprehensive postgraduate program
in Ai and machine learning boost your
careers with this course delivered in
collaboration with Purdue University and
IBM learn in-demand skills such as
machine learning deep learning NLP
computer vision reinforcement learning
gender DBI prompt to engineering
charitivity and many more you will
receive a prestigious certificate and
ask me anything session by IBM that's
five caps shown in different domain
using real data set you will gain
practical experience master classes by
power difficulty and IBM expert ensure
top-notch education simply learn job
assist help you get noticed by Leading
companies this programs cover statistic
python supervised and unsupervised
learning NLP neural network computer
vision Gans Keras tensorflow and many
more skills admission to this
postgraduate program in AIML course
requires two plus years of work
experience preferred a bachelor degree
with an average 50 percent or higher
marks basic understanding of programming
Concepts and Mathematics so why wait
enroll now and unlock exciting AIML
opportunities the link is in the
description box below so without any
further Ado over to our training expert
it's a weekend and John decided to watch
the latest movie recommended by Netflix
at his friends place
before heading out he asked Siri about
the weather and realized it would rain
so he decided to take his Tesla for the
long journey and switch to autopilot on
the highway
after coming home from the eventful day
he started wondering how technology has
made his life easy
he did some research on the internet and
found out that Netflix Siri and Tesla
are all using AI
so what is AI
AI or artificial intelligence is nothing
but making computers-based machines
think and act like humans
artificial intelligence is not a new
term John McCarthy a computer scientist
coined the term artificial intelligence
back in 1956
but it took time to evolve as it
demanded heavy computing power
artificial intelligence is not confined
to just movie recommendations and
virtual assistants
broadly classifying there are three
types of AI
artificial narrow intelligence also
called weak AI is the stage where
machines can perform a specific task
Netflix Siri chat Bots spatial
recommendation systems are all examples
of artificial narrow intelligence
next up we have artificial general
intelligence referred to as an
intelligent agent's capacity to
comprehend or pick up any intellectual
skill that a human can
we are halfway in a successfully
implementing this space IBM's Watson
supercomputer and gpt3 fall under this
category and lastly artificial super
intelligence it is the stage where
machines surpass human intelligence you
might have seen this in movies and
imagined how the world would be if
machines occupied
fascinated by this John did more
research and found out that machine
learning deep learning and natural
language processing are all connected
with artificial intelligence
machine learning a subset of AI is the
process of automating and enhancing how
computers learn from their experiences
without human help
machine learning can be used in email
spam detection medical diagnosis Etc
deep learning can be considered a subset
of machine learning it is a field that
is based on learning and improving on
its own by examining computer algorithms
while machine learning uses simpler
Concepts deep learning works with
artificial neural networks which are
designed to imitate the human brain this
technology can be applied in face
recognition speech recognition and many
more applications
natural language processing popularly
known as NLP can be defined as the
ability of machines to learn human
language and translate it chat Bots fall
under this category
artificial intelligence is advancing in
every crucial field like healthcare
education robotics banking e-commerce
and the list goes on
like in healthcare AI is used to
identify diseases helping healthcare
service providers and their patients
make better treatment and lifestyle
decisions
coming to the education sector AI is
helping teachers automate grading
organizing and facilitating parent
Guardian conversations
in robotics ai-powered robots employ
real-time updates to detect obstructions
in their path and instantaneously design
the racks artificial intelligence
provides Advanced data analytics that is
transforming banking by reducing fraud
and enhancing compliance
with this growing demand for AI more and
more Industries are looking for AI
Engineers who can help them develop
intelligent systems and offer them
lucrative salaries going north of one
hundred and twenty thousand dollars
the future of AI looks promising with
the AI Market expected to reach 190
billion dollars by 2025.
artificial intelligence is reshaping
Industries and transforming the way we
will leave and work it encompasses a
wide range of Technologies including
machine learning deep learning natural
language processing computer vision and
many more with its ability to analyze
vast amount of data and make Intelligent
Decisions AI has become a game changer
across various domains hi everyone
welcome to Simply learns YouTube channel
this AI roadmap guides you in navigating
the path towards building a successful
career in artificial intelligence the
ultimate goal of artificial intelligence
is to create intelligent missions that
can perform complex tasks exhibit
human-like intelligence and contribute
positivity to society AI presents
exciting career opportunity in various
Industries and sectors roles like AI
engineer data scientists NLP Engineers
computer vision Engineers AI research
scientists robotic engineers and many
more offer exciting prospects for
working with Cutting Edge Technologies
and making an impact through artificial
intelligence Innovation according to
last doubt the average reported salary
of an AI engineer in the United States
is around 105
000 per year however in India it is
still like per annum leading companies
worldwide are fully aware of the immense
value of AI and are actively pursuing
skilled AI Engineers to contribute to
their research development and
implementations of AI technology among
this top companies are Google Microsoft
Amazon Goldman Sachs apple and JPMorgan
Chase therefore top companies hiring AI
engineer provide excellent opportunity
for aspiring professionals on that note
eliminate your career with our Ai and ml
course developed in partnership with
Purdue University and IBM gain expertise
in high demand skills such as machine
learning deep learning NLP computer
vision reinforcement learning charge GPT
generative Ai explainable Ai and more
Unleash Your Potential and unlock
exciting opportunity in the world of AI
and ml this course cover tools like
python tensorflow
so hurry up and find the course Link in
the description box for more details our
Learners have experienced huge success
in their careers listen to their
experience find the simply learn course
reviews Link in the description box
without any further delay let's dive
into the topic now if you decide to
become an AI engineer here are the steps
you can follow to achieve your goal
firstly obtain a strong foundation in
mathematics and programming gain a
strong foundation in creating mathematic
Concepts like linear algebra calculus
and probability theory in addition to
that it is crucial to occur Mastery of a
programming languages like python
commonly used in Ai and become
proficient in coding then earn a degree
in a relevant field that means earn a
bachelor's or master degree in computer
science data science AI or a related
field to gain a comprehensive
understanding of AI principles and
techniques next gain knowledge in
machine learning and deep learning to
become a AI engineer develop similarity
with ML algorithms neural networks and
deep learning Frameworks example
tensorflow by torch to train and
optimize models using real world data
set followed by that work on practical
projects gain hands-on experience and
showcase your skills by working on AI
projects moreover build a portfolio of
projects demonstrating your ability to
solve EI problems impressing potential
employers then stay updated with the
latest advancements stay updated with
the latest trends and research in AI a
rapidly involved field and expanding
your knowledge by reading research
papers participating in online courses
and workshops and joining AI communities
next collaborate and network engage with
AI communities attend conference
participate in online forums to connect
with Professionals in this field
collaborating with others can enhance
your learning experience and open new
opportunities later seek internships or
entry-level positions gain practical
experience through AI internships or
entry level roles in industry or
research institutions this provides
valuable exposures and help develop your
skills finally continuously learn and
adapt in the rapidly involving field of
AI stay updated on new developments
explore specialized areas and embrace
emerging Technologies and tools to
pursue a career as an AI engineer now
that we have covered the essential steps
to become an AI engineer let's explore
the necessary programming languages and
algorithms for aspiring AI Engineers so
mastering programming languages like
python are Java and C plus plus is vital
for occurring Proficiency in AI this
language is enables you to construct and
deploy models effectively additionally
it would help if you gain a thorough
understanding of machine learning
algorithms such as linear regressions K
nearest neighbors nif base and support
Vector missions these languages and
algorithms are fundamental tools in the
field of AI they will enable you to
develop and Implement effective
artificial intelligence models hello
require
D with the adventure of artificial
intelligence and its Superior abilities
to improve human life the need and
demand for expert AI professional is at
an all-time high this expanding demand
has led to a lot of people applying for
AI jobs and upskilling themselves in the
field of AI but doing this is just like
playing a game but not knowing its rules
for someone to become an air
professional and land a job like an AI
engineer they first have to understand
the demand from this role and what the
skills are expected of an AI engineer so
if you are someone who wishes to become
an AI engineer or if you wish to upgrade
your skills in Ai and get promoted as an
AI engineer then make sure you watch
this amazing video till the very end in
this video we will be breaking down in
complete detail each and every skill
that you would need in order to crack an
AI engineer job interview but why should
you consider career in AI
AI is not just a passing Trend it's a
systemic ship that is reshaping our
world and creating new avenues for
Innovation and discovery by embracing a
career in AI you become a part of
dynamic field that thrives on solving
complex problems pushing boundaries and
making a profound impact on society the
demand for AI professional is
skyrogating across industries from
Healthcare and finance to entertainment
and transportation organization are
actively seeking talented individuals
who can harness the power of AI to drive
their business forward but what excuse
does it take to become an AI engineer
how can you embark on the thrilling
Journey we have answered to all of your
questions also accelerate your career in
Ai and ml without comprehensive
postgraduate program in AI animal
machine learning gain expertise in
machine learning deep learning NLP
computer vision and reinforcement
learning you will receive a prestigious
certificate exclusive aluminum
membership and ask me anything session
by IBM with three Capstone project and
25 plus industry projects using real
data set from Twitter Uber and many more
you will gain practical experience
master classes by Caltech faculty and
IBM expert ensure top-notch education
simply learn job assist help you to get
notice by Leading companies this program
covers statistic python supervised and
unsupervised learning NLP neural network
computer vision Gans Keras tensorflow
and many more skills so enroll now and
unlock exciting Ai and ml opportunities
the link is in the description box below
so without any further delay let's get
started some steps are crucial to master
in the field of AI and becoming an AI
engineer let's go through them real
quick first establish a strong
foundation in mathematics and
programming
start by gaining a solid understanding
of critical Concepts like linal algebra
calculus and probability Theory
additionally it is crucial to become
proficient in programming language like
python which is commonly used in Ai and
developed coding skills
and the next one is pursue a degree in
relevant field on a bachelor or master
degree in computer science data science
or AI or related discipline to acquire
comprehensive understanding of AI
principles and techniques then acquire
knowledge in machine learning and deep
learning familiarize yourself with ML
algorithms neural networks and deep
learning Frameworks that is tensorflow
and Pi torch to train and optimize
models using real-world data sets
afterward engage in Practical projects
gain hands-on experience and demonstrate
your skills by working on AI projects
building a portfolio of projects that
showcase your ability to solve AI
problems can make a strong impression on
potential employers and the fifth one is
collaborate and network engage with
communities attend conferences and
participate in the online forums to
connect with the Professionals in the
field collaborating with others can
enhance your learning experience and
open up new opportunities and the sixth
one is seek internship or entry level
positions gain practical experience
through AI internship or entry level
roles in Industries or research
institutions this will provide valuable
exposure and help you further develop
your skill and at the last continuously
learning and adapt in the first place
world of EI it is crucial to stay
updated on new developments explore
specialized ideas and embrace emerging
Technologies and tools continuous
learning and adaptability are essential
for purchasing a successful career as a
AI engineer so now that you are familiar
with the steps involved in the Journey
of AI engineer let's have a look at the
salary of an AI engineer
so according to Glassdoor the average
reported salary of an AI engineer in the
United States is 105
000 per year however in India it is 10
lakh per annum
so these figures are way better than the
average salary figures of any job rule
so let's discuss
the skills you need to become an AI
engineer you should have a strong
background in data science and machine
learning here is a breakdown of your
skills number one strong programming
abilities they typically refers to
expertise in one or more programming
languages commonly used in data science
and machine learning such as Python and
R Proficiency in programming allows you
to write efficient and scalable code for
data analysis modeling and algorithm
implantation and the second one is
knowledge of machine learning algorithms
this involves understanding and
familiarity with the void range of
machine learning algorithm including
both supervised and unsupervised
learning you should be able to select
and apply appropriate algorithm for a
specific problem as well as evaluate and
optimize their performance
and the third one is Proficiency in
statistics and Mathematics sound
knowledge of statistics and Mathematics
is fundamental for data analysis and
machine learning you should be
comfortable with statical Concept
hypothesis testing regression analysis
probability Theory and algebra and
calculus and the fourth one is
familiarity with deep learning
Frameworks deep learning has gained
significant popularity in recent years
and familiarity with deep learning
Frameworks like tensorflow Pi torch or
Keras is valuable these Frameworks
provide tools and libraries for building
training and deploying deep neural
networks for tasks such as image
recognition natural language processing
and time series analysis
and the fifth one is
experience with big data Technologies
dealing with large scale data set
requires knowledge of Big Data
Technologies such as Apache Hadoop or
Apache spark or distributed computing
Frameworks understanding how to process
store and analyze data efficiently in
distributed environment and the sixth
one is excellent problem solving and
analytical skills these skills enable
you to break down complex problem
identify key factors and develop
effective Solutions
you should be Adept at critical thinking
troubleshooting and debugging to handle
real world challenges in the data
science and machine learning remember to
stay updated with the latest advancement
in the field and continual learning to
stay at the Forefront of data science
and machine learning first let's
understand what really is artificial
intelligence
artificial intelligence is the science
of building intelligent machines from
vast volumes of data
this data can be structured
semi-structured or unstructured in
nature
AI systems learn from past experiences
and perform human-like tasks artificial
intelligence enhances the speed decision
and effectiveness of human efforts
AI uses sophisticated algorithms and
methods to build machines that can make
decisions on their own deep learning and
machine learning are the two subsets of
artificial intelligence so you need both
machine learning algorithms and deep
learning networks to build intelligent
systems
AI is now being widely used in almost
every sector of business such as
Transportation Healthcare banking retail
entertainment and e-commerce
now let's look at the different types of
artificial intelligence
so AI can be classified based on
capabilities and functionalities
under capabilities there are three types
of artificial intelligence
they are narrow AI General Ai and super
AI
under functionalities we have four types
of artificial intelligence reactive
machine limited memory theory of mind
and self-awareness let's look at them
one by one
first we will look at the different
types of artificial intelligence based
on capabilities
so what is narrow AI
narrow AI also known as vki focuses on
one narrow task and cannot perform
Beyond its limitations
it aims at a single subset of cognitive
abilities and advances in that Spectrum
applications of narrow AI are becoming
increasingly common in our day-to-day
lives as machine learning and deep
learning methods continue to evolve
Apple Siri is a simple example of an
arrow AI that operates with a limited
predefined range of functions
Siri often has challenges with tasks
outside its range of abilities IBM
Watson supercomputer is another example
of narrow AI which applies cognitive
Computing machine learning and natural
language processing to process
information and answer your questions
IBM Watson once outperformed human
contestant Ken Jenkins to become the
champion on the popular game show
Jeopardy other examples of narrow AI
include Google Translate image
recognition software recommendation
systems spam filtering and Google's page
ranking algorithm
next we have General artificial
intelligence or general AI General AI
also known as strong AI has the ability
to understand and learn any intellectual
task that a human can
General artificial intelligence has
received a one billion dollar investment
from Microsoft through open AI it allows
a machine to apply Knowledge and Skills
in different contexts AI researchers and
scientists have not achieved strong AI
so far to succeed they would need to
find a way to make machines conscious
programming a full set of cognitive
abilities
Fujitsu built the K computer which is
one of the fastest computers in the
world
it is one of the most notable attempts
at achieving strong AI
it took 40 minutes to simulate a single
second of neural activity so it is
difficult to determine whether or not
strong AI will be achieved in the near
future
tan HE2 is a supercomputer created by
China's national university of Defense
technology
it currently holds the record for CPS at
33.86 petaflops although it sounds
exciting the human brain is estimated to
be capable of One exaph log
now CPS means characters per second that
A system can process
third in the list of AI that is based on
capabilities we have super AI
super AI exceeds human intelligence and
can perform any tasks better than a
human
the concept of artificial super
intelligence sees AI evolved to be so
akin to human emotions and experiences
that it doesn't just understand them it
evokes emotions needs beliefs and
desires of its own its existence is
still hypothetical some of the key
characteristics of super AI include the
ability to think solve puzzles meet
judgments and decisions on its own
now if you have enjoyed watching this
video so far please make sure to
subscribe to our YouTube channel and hit
the Bell icon to stay updated with all
the latest Technologies also if you have
any questions related to this video
please put it in the chat section A team
of experts will help you address your
questions
moving ahead now we will see the
different types of artificial
intelligence based on functionalities
in this category first we have reactive
machine
a reactive machine is the basic form of
AI that does not store memories or use
past experiences to determine future
actions
it works only with present data they
simply perceive the world and react to
it reactive machines are given certain
tasks and don't have capabilities Beyond
those duties
IBM's deep blue which defeated just
Grand Master Gary Castro is a reactive
machine that sees the pieces on HS code
and reacts to them
it cannot refer to any of its prior
experiences and cannot improve with
practice
deep blue can identify the pieces on a
chessboard and know how each moves
it can make predictions about what moves
might be next for it and its opponent
it can choose the most optimal moves
from among the possibilities deep blue
ignores everything before the present
moment
all it does is look at the pieces on the
chessboard as it stands right now and
choose from possible next moves
up next we have limited memory
limited memory AI learns from past data
to make decisions
the memory of such systems is
short-lived
while they can use this data for a
specific period of time they cannot add
it to a library of their experiences
this kind of technology is used for
self-driving vehicles
they observe how other vehicles are
moving around them in the present and as
time passes
that ongoing collected data gets added
to the static data within the AI machine
such as lean markers and traffic lights
they are included when the vehicle
decides to change lanes to avoid cutting
of another driver or being hit by a
nearby vehicle
Mitsubishi Electric is a company that
has been figuring out how to improve
such technology for applications like
self-driving cars
then we have theory of mind
theory of Mind represents a very
advanced class of technology and exists
as a concept this kind of AI requires a
thorough understanding that the people
and the things within an environment can
alter feelings and behaviors
it should be able to understand people's
emotions sentiment and thoughts
even though a lot of improvements are
there in this field this kind of AI is
not complete yet
one real world example of theory of Mind
AI is Kismet a robot had made in the
late 90s by a Massachusetts Institute of
Technology researcher Kismet can make
human emotions and recognize them both
abilities are key advancements in theory
of Mind AI but Kismet can't follow gazes
or convey attention to humans
Sophia from Hanson robotics is another
example where the theory of Mind AI was
implemented cameras within Sofia's eyes
combined with computer algorithms allow
her to see
sick and follow faces sustain eye
contact and recognize individuals
is able to process speech and have
conversations using natural language
subsystem
finally we have self-awareness
self-awareness AI only exists
hypothetically
such systems understand that internal
traits States and conditions and
perceive human emotions
these machines will be smarter than the
human mind
this type of AI will not only be able to
understand and evoke emotions in those
it interacts with but also have emotions
needs and beliefs of its own
while we are probably far away from
creating machines that are self-aware we
should focus our efforts towards
understanding memory learning and the
ability to base decisions on past
experiences let's look at the definition
of each of these learning techniques
supervised learning uses labeled data to
train machine learning models labeled
data means that the output is already
known to you
the model just needs to map the inputs
to the outputs an example of supervised
learning can be to train a machine that
identifies the image of an animal
below you can see we have a trend model
that identifies the picture of a cat
unsupervised learning uses unlabeled
data to train machines unlabeled data
means there is no fixed output variable
the model learns from the data discovers
patterns and features in the data and
Returns the output here is an example of
an unsupervised learning technique that
uses the images of vehicles to classify
if it's a bus or a truck
so the model learns by identifying the
parts of a vehicle such as the length
and width of the vehicle the front and
rear end covers roof hoods the types of
Wheels used Etc based on these features
the model classifies if the vehicle is a
bus or a truck
reinforcement learning drains a machine
to take suitable accents and maximize
reward in a particular situation
it uses an agent and an environment to
produce actions and Rewards
the agent has a start and an end state
but there might be different parts for
reaching the end State like a maze in
this learning technique there is no
predefined target variable an example of
reinforcement learning is to train a
machine that can identify the shape of
an object given a list of different
objects such as square triangle
rectangle or a circle
in the example shown the model tries to
predict the shape of the object which is
a square here
now
let's look at the different machine
learning algorithms that come under
these learning techniques
some of the commonly used supervised
learning algorithms are linear
regression logistic regression support
Vector machines K nearest neighbors
decision tree random forest and knife
base
examples of unsupervised learning
algorithms are key means clustering
hierarchical clustering DB scan
principle component analysis and others
choosing the right algorithm depends on
the type of problem you are trying to
solve
some of the important reinforcement
learning algorithms are Q learning Monte
Carlo sarsa and deep Q Network now let's
look at the approach in which these
machine learning techniques work
so supervised learning takes labeled
inputs and Maps it to known outputs
which means you already know the target
variable
unsupervised learning finds patterns and
understands the trends in the data to
discover the output so the model tries
to label the data based on the features
of the input data
while reinforcement learning follows
trial and error method to get the
desired solution after accomplishing a
task the agent receives an award
an example could be to train a dog to
catch the ball if the dog learns to
catch a ball you give it a reward such
as a biscuit
now let's discuss the training process
for each of these learning methods
so supervised learning methods need
external supervision to train machine
learning models and hence the name
supervised
they need guidance and additional
information to return the result
unsupervised learning techniques do not
need any supervision to train models
they learn on their own and predict the
output
similarly reinforcement learning methods
do not need any supervision to train
machine learning models
and with that
let's focus on the types of problems
that can be solved using these three
types of machine learning techniques so
supervised learning is generally used
for classification and regression
problems we'll see the examples in the
next slide
an unsupervised learning is used for
clustering and Association problems
while reinforcement learning is reward
based so for every task or for every
step completed there will be a reward
received by the agent
and if the task is not achieved
correctly
there will be some penalty used
now let's look at a few applications of
supervised unsupervised and
reinforcement learning
as we saw earlier supervised learning
are used to solve classification and
regression problems for example You can
predict the weather for a particular day
based on humidity precipitation wind
speed and pressure values
you can use supervised learning
algorithms to forecast sales for the
next month or the next quarter for
different products similarly you can use
it for stock price analysis or
identifying if a cancer cell is
malignant or benign
now talking about the applications of
unsupervised learning we have customer
segmentation So based on customer
Behavior likes dislikes and interests
you can segment and cluster similar
customers into a group another example
where unsupervised learning algorithms
are used is customer churn analysis
now let's see what applications we have
in reinforcement learning so
reinforcement learning algorithms are
widely used in the gaming Industries to
build games it is also used to train
robots to perform human tasks profit
estimation of a company if I was going
to invest in a company I would like to
know how much money I could expect to
make so we'll take a look at a venture
capitalist firm and try to understand
which companies they should invest in so
we'll take the idea that we need to
decide the companies to invest in we
need to predict the profit the company
makes and we're going to do it based on
the company's expenses and even just a
specific expense in this case we have
our company we have the different
expenses so we have our r d which is
your research and development we have
our marketing we might have the location
we might have what kind of
administrations going through based on
all this different information we would
like to calculate the profit now in
actuality there's usually about 23 to 27
different markers that they look at if
they're a heavy duty investor we're only
going to take a look at one basic one
we're going to come in and for
Simplicity let's consider a single
variable R and D and find out which
companies to invest in based on that so
we take our r d and we're plotting The
Profit based on the r d expenditure how
much money they put into the research
and development and then we look at the
profit that goes with that we can
predict a line to estimate the profit so
we draw a line right through the data
when you look at that you can see how
much they invest in the r d is a good
marker as to how much profit they're
going to have we can also note that
companies spending more on R D make good
profit so let's invest in the ones that
spend a higher rate in their r d what's
in it for you first we'll have an
introduction to machine learning
followed by Machine learning algorithms
these will be specific to linear
regression and where it fits into the
larger model then we'll take a look at
applications of linear regression
understanding linear regression and
multiple linear regression finally we'll
roll up our sleeves and do a little
programming in use case profit
estimation of companies let's go ahead
and jump in let's start with our
introduction to machine learning along
with some machine learning algorithms
and where that fits in with linear
regression let's look at another example
of machine learning based on the amount
of rainfall how much would be the crop
yield so here we have our crops we have
our rainfall and we want to know how
much we're going to get from our crops
this year so we're going to introduce
two variables independent and dependent
the independent variable is a variable
whose value does not change by the
effect of other variables and is used to
manipulate the dependent variable it is
often denoted as X in our example
rainfall is the independent variable
this is a wonderful example because you
can easily see that we can't control the
rain but the rain does control the crop
so we talk about the independent
variable controlling the dependent
variable let's Define dependent variable
as a variable whose value change when
there is any manipulation the values of
the independent variables it is often
denoted as Y and you can see here our
crop yield this dependent variable and
it is dependent on the amount of
rainfall received now that we've taken a
look at a real life example let's go a
little bit into the theory and some
definitions on machine learning and see
how that fits together with linear
regression numerical and categorical
values let's take our data coming in and
this is kind of random data from any
kind of project we want to divide it up
into numerical and categorical so
numerical is numbers age salary height
where categorical would be a description
the color a dog's breed gender
categorical is limited to very specific
items where numerical is a range of
information now that you've seen the
difference between numerical and
categorical data let's take a look at
some different machine learning
definitions when we look at a different
machine learning algorithms we can
divide them into three areas supervised
unsupervised reinforcement we're only
going to look at supervise today
unsupervised means we don't have the
answers we're just grouping things
reinforcement is where we give positive
and negative feedback to our algorithm
to program it and it doesn't have the
information until after the fact but to
today we're just looking at supervised
because that's where linear regression
fits in in supervised data we have our
data already there and our answers for a
group and then we use that to program
our model and come up with an answer the
two most common uses for that is through
the regression and classification now
we're doing linear regression so we're
just going to focus on the regression
side and in the regression we have
SIMPLE linear regression we have
multiple linear regression and we have
polynomial linear regression now on
these three simple linear regression is
the examples we've looked at so far
where we have a lot of data and we draw
a straight line through it multiple
linear regression means we have multiple
variables remember where we had the
rainfall and the crops we might add
additional variables in there like how
much food do we give our crops when do
we Harvest them those would be
additional information add into our
model and that's why it'd be multiple
linear regression and finally we have
polynomial linear regression that is
instead of drawing a line we can draw a
curved line through it it now that you
see where regression model fits into the
machine learning algorithms and we're
specifically looking at linear
regression let's go ahead and take a
look at applications for linear
regression let's look at a few
applications of linear regression
economic growth used to determine the
economic growth of a country or a state
in the coming quarter can also be used
to predict the GDP of a country product
price can be used to predict what would
be the price of a product in the future
we can guess whether it's going to go up
or down or should I buy today housing
sales to estimate the number of houses a
builder would sell and what price in the
coming months score predictions Cricket
fever to predict the number of runs a
player would score in the coming matches
based on the previous performance I'm
sure you can figure out other
applications you could use linear
regression for so let's jump in and
let's understand linear regression and
dig into the theory understanding linear
regression linear regression is the
statistical model used to predict the
relationship between independent and
dependent variables by examining two
factors the first important one is which
variables in particular are significant
predictors of the outcome variable and
the second one that we need to look at
closely is how significant is the
regression line to make predictions with
the highest possible accuracy if it's
inaccurate we can't use it so it's very
important we find out the most accurate
line we can get since linear regression
is based on drawing a line through data
we're going to jump back and take a look
at some euclidean geometry the simplest
form of a simple linear regression
equation with one dependent and one
independent variable is represented by y
equals m times X plus C and if you look
at our model here we plotted two points
on here X1 and y1 X2 and Y2 y being the
dependent variable remember that from
before and X being the independent
variable so y depends on whatever X is m
in this case is the slope of the line
where m equals the difference in the Y2
minus y1 and X2 minus X1 and finally we
have C which is the coefficient of the
line or where it happens to cross the
zero axes let's go back and look at an
example we used earlier of linear
regression we're going to go back to
plotting the amount of crop yield based
on the amount of rainfall and here we
have our rainfall remember we cannot
change rainfall and we have our crop
yield which is dependent on the rainfall
so we have our independent and our
dependent variables we're going to take
this and draw a line through it as best
we can through the middle of the data
and then we look at that we put the red
point on the y-axis is the amount of
crop yield you can expect for the amount
of rainfall represented by the Green Dot
so if we have an idea what the rainfall
is for this year and what's going on
then we can guess how good our crops are
going to be and we created a nice line
right through the middle to give us a
nice mathematical formula let's take a
look and see what the math looks like
behind this let's look at the intuition
behind the regression line now before we
dive into the math and the formulas that
go behind this and what's going on
behind the scenes
I want you to note that when we get into
the case study and we actually apply
some python script that this math you're
going to see here is already done
automatically for you you don't have to
have it memorized it is however good to
have an idea what's going on so if
people reference the different terms
you'll know what they're talking about
let's consider a sample data set with
five rows and find out how to draw the
regression line we're only going to do
five rows because if we did like the
rainfall with hundreds of points of data
that would be very hard to see what's
going on with the mathematics so we'll
go ahead and create our own two sets of
data and we have our independent
variable X and our dependent variable Y
and when X was one we got y equals 2
when X was 2 y was 4 and so on and so on
if we go ahead and plot this data on a
graph we can see how it forms a nice
line through the middle you can see
where it's kind of grouped going upwards
to the right the next thing we want to
know is what the means is of each of the
data coming in the X and the Y the means
doesn't mean anything other than the
average so we add up all the numbers and
divide by the total so one plus two plus
three plus four plus five over five
equals three and the same for y we get
four if we go ahead and plot the means
on the graph we'll see we get three
comma four which draws a nice line down
the middle a good estimate here we're
going to dig deeper into the math behind
the regression line now remember before
I said you don't have to have all these
formulas memorized or fully understand
them even though we're going to go into
a little more detail of how it works and
if you're not a math whiz and you don't
know if you've never seen the sigma
character before which looks a little
bit like an e that's opened up that just
means summation that's all that is so
when you see the sigma character it just
means we're adding everything in that
row and for computers this is great
because as a programmer you can easily
iterate through each of the X Y points
and create all the information you need
so in the top half you can see where
we've broken that down into pieces and
as it goes through the first two points
it computes the squared value of x the
squared value of y and x times Y and
then it takes all of X and adds them up
all of Y adds them up all of x squared
adds them up and so on and so on and you
can see we have the sum of equal to 15
the sum is equal to 20 all the way up to
x times Y where the sum equals 66 this
all comes from our formula for
calculating a straight line where y
equals the slope times X plus the
coefficient C so we go down below and
we're going to compute more like the
averages of these and we'll explain
exactly what that is in just a minute
and where that information comes from is
called the square means error but we'll
go into that in detail in a few minutes
all you need to do is look at the
formula and see how we've gone about
Computing it line by line instead of
trying to you have a huge set of numbers
pushed into it and down here you'll see
where the slope m equals and then the
top part if you read through the
brackets you have the number of data
points times the sum of x times Y which
we computed one line at a time there and
that's just the 66 and take all that and
you subtract it from the sum of x times
the sum of Y and those have both been
computed so you have 15 times 20. and on
the bottom we have the number of lines
times the sum of x squared easily
computed as 86 for the sum minus I'll
take all that and subtract the sum of x
squared and we end up as we come across
with our formula you can plug in all
those numbers which is very easy to do
on the computer you don't have to do the
math on a piece of paper or calculator
and you'll get a slope of 0.6 and you'll
get your C coefficient if you continue
to follow through that formula you'll
see it comes out as equal to 2.2
continuing deeper into what's going
behind the scenes let's find out the
predicted values of Y for corresponding
values of X using the linear equation
where m equals 0.6 and C equals 2.2
we're going to take these values and
we're going to go ahead and plot them
we're going to predict them so y equals
0.6 times where x equals 1 plus 2.2
equals 2.8 and so on and so on and here
the Blue Points represent the actual y
values and the brown points represent
the predicted y values based on the
model we created the distance between
the actual and predicted values is known
as residuals or errors the best fit line
should have the least sum of squares of
these errors also known as e-square if
we put these into a nice chart we can
see X and you can see Y what the actual
values were and you can see why it
predicted you can easily see where we
take y minus y predicted and we get an
answer what is the difference between
those two and if we square that y minus
y prediction squared we can then sum
those squared values that's where we get
the 0.64 plus the 0.36 plus 1 all the
way down until we have a summation
equals 2.4 so the sum of squared errors
for this regression line is 2.4 we check
this error for each line and conclude
the best fit line having the least e
Square value in a nice graphical
representation we can see here where we
keep moving this line through the data
points to make sure the best fit line
has the least squared distance between
the data points and the regression line
now we only looked at the most commonly
used formula for minimizing the distance
there are lots of ways to minimize the
distance between the line and the data
points like sum of squared errors sum of
absolute errors root mean square error
Etc which you want to take away from
this is whatever formula is being used
you can easily using a computer
programming and iterating through the
data calculate the different parts of it
that way these complicated formulas you
see with the different summations and
absolute values are easily computed one
piece at a time up until this point
we've only been looking at two values X
and Y well in the real world it's very
rare that you only have two values when
you're figuring out a solution so let's
move on to the next topic multiple
linear regression let's take a brief
look at what happens when you have
multiple inputs so in multiple linear
regression we have well we'll start with
the simple linear regression where we
had y equals M plus X plus C and we're
trying to find the value of y now with
multiple linear regression we have
multiple variables coming in so instead
of having just X we have X1 X2 X3 and
instead of having just one slope each
variable has its own slope attached to
it as you can see here we have M1 M2 M3
and we still just have the single
coefficient so when you're dealing with
multiple linear regression you basically
take your single linear regression and
you spread it out so you have y equals
M1 times X1 1 plus M2 times X2 so on all
the way to m to the nth x to the nth and
then you add your coefficient on there
implementation of linear regression now
we get into my favorite part let's
understand how multiple linear
regression works by implementing it in
Python if you remember before we were
looking at a company and just based on
its R and D trying to figure out its
profit we're going to start looking at
the expenditure of the company we're
going to go back to that we're going to
predict as profit but instead of
predicting it just on the R and D we're
going to look at other factors like
Administration costs marketing costs and
so on and from there we're going to see
if we can figure out what the profit of
that company is going to be to start our
coding we're going to begin by importing
some basic libraries and we're going to
be looking through the data before we do
any kind of linear regression we're
going to take a look at the data to see
what we're playing with then we'll go
ahead and format the data to the format
we need to be able to run it in the
linear regression model and then from
there we'll go ahead and solve it and
and just see how valid our solution is
so let's start with importing the basic
libraries now I'm going to be doing this
in Anaconda Jupiter notebook a very
popular IDE I enjoy because it's such a
visual to look at it's so easy to use
just any ID for python will work just
fine for this so break out your favorite
python IDE so here we are in our Jupiter
notebook let me go ahead and paste our
first piece of code in there and let's
walk through what libraries were
importing first we're going to import
numpy as NP and then I want you to skip
one line and look at import pandas as PD
these are very common tools that you
need with most of your linear regression
the numpy which stands for number python
is usually denoted as NP and you have to
almost have that for your SK learn
toolbox you always import that right off
the beginning pandas although you don't
have to have it for your sklearn
libraries it does such a wonderful job
of importing data setting it up into a
data frame so we can manipulate it
rather easily and it has a lot of tools
also in addition to that so so we
usually like to use the pandas when we
can and I'll show you what that looks
like the other three lines are for us to
get a visual of this data and take a
look at it so we're going to import
matplotlibrary.pi plot as PLT and then
Seaborn as SNS Seabourn works with the
matplot library so you have to always
import matplot library and then Seaborn
sits on top of it and we'll take a look
at what that looks like you could use
any of your own plotting libraries you
want there's all kinds of ways to look
at the data these are just very common
ones and the Seaborn is so easy to use
it just looks beautiful it's a nice
representation that you can actually
take and show somebody and the final
line is the Amber signed matplot library
in line that is only because I'm doing
an inline IDE my interface in the
Anaconda Jupiter notebook requires I put
that in there or you're not going to see
the graph when it comes up let's go
ahead and run this it's not going to be
that interesting so we're just setting
up variables in fact it's not going to
do anything that we can see but it is
importing these different libraries and
setup the next step is load the data set
and extract independent and dependent
variables now here in this slide you'll
see companies equals pd.read CSV and it
has a long line there with the file at
the end one thousand companies.csv
you're going to have to change this to
fit whatever setup you have and the file
itself you can request just go down to
the commentary below this video and put
a note in there and simply learn we'll
try to get in contact with you and
Supply you with that file so you can try
this coding yourself so we're going to
add this code in here and we're going to
see that I have companies equals
pd.reader underscore CSV and I've
changed this path to match my computer C
colon slash simply learn slash 1000
underscore companies.csv and then below
there we're going to set the x equals to
companies under the I location and
because this is companies is a PD data
set I can use this nice notation that
says take every row that's what the
colon the first colon is comma except up
for the last column that's what the
second part is where we have a colon
minus one and we want the values set
into there so X is no longer a data set
a panda's data set but we can easily
extract the data from our pandas data
set with this notation and then y we're
going to set equal to the last row well
the question is going to be what are we
actually looking at so let's go ahead
and take a look at that and we're going
to look at the companies.head which
lists the first five rows of data and
I'll open up the file in just a second
so you can see where that's coming from
but let's look at the data in here as
far as the way the pandas sees it when I
hit run you'll see it breaks it out into
a nice setup this is what pandas one of
the things pandas is really good about
is it looks just like an Excel
spreadsheet you have your rows and
remember when we're programming we
always start with zero we don't start
with one so it shows the first five rows
zero one two three four and then it
shows your different columns R and D
spend Administration marketing spend
State profit it even notes that the top
top are column names it was never told
that but pandas is able to recognize a
lot of things that they're not the same
as the data rows why don't we go ahead
and open this file up in a CSV so you
can actually see the raw data so here
I've opened it up as a text editor and
you can see at the top we have r d spend
comma Administration comma marketing
spin comma State comma profit carries
return I don't know about you but I'd go
crazy trying to read files like this
that's why we use the pandas you could
also open this up in an Excel and it
would separate it since it is a comma
separated variable file but we don't
want to look at this one we want to look
at something we can read rather easily
so let's flip back and take a look at
that top part the first five row now as
nice as this format is we can see the
data to me it doesn't mean a whole lot
maybe you're an expert in business and
Investments and you understand what 165
349.20 compared to the administration
cost of 136
897.80 so on so on helps to create the
the profit of 192 261 and 83 cents that
makes no sense to me whatsoever no pun
intended so let's flip back here and
take a look at our next set of code
where we're going to graph it so we can
get a better understanding of our data
and what it means so at this point we're
going to use a single line of code to
get a lot of information so we can see
where we're going with this let's go
ahead and paste that into our notebook
and see what we got going and so we have
the visualization and again we're using
SNS which is pandas as you can see we
imported the matplot Library dot Pi plot
is PLT which then the Seaborn uses and
we imported the Seaborn as SNS and then
that final line of code helps us show
this in our inline coding without this
it wouldn't display and you could
display it to a file in other means and
that's the matplot library in line with
the Amber sign at the beginning so here
we come down to the single line of code
Seaborn is great because it actually
recognizes the panda data frame so I can
just take the com companies dot core for
coordinates and I can put that right
into the Seaborn and when we run this we
get this beautiful plot and let's just
take a look at what this plot means if
you look at this plot on mine the colors
are probably a little bit more purplish
and blue than the original one we have
the columns and the rows we have R and D
spending we have Administration we have
marketing spending and profit and if you
cross index any two of these since we're
interested in profit if you cross index
profit with profit it's going to show up
if you look at the scale on the right
way up in the dark why because those are
the same data they have an exact
correspondence so r d spending is going
to be the same as r d spending and the
same thing with Administration costs so
right down the middle you get this dark
row or dark diagonal row that shows that
this is the highest corresponding data
that's exactly the same and as it
becomes lighter there's less connections
between the data so we can see with
profit obviously profit is the same as
profit and next it has a very high
correlation with r d spending which we
looked at earlier and it has a slightly
less connection to marketing spending
and even less to how much money we put
into the administration so now that we
have a nice look at the data let's go
ahead and dig in and create some actual
useful linear regression models so that
we can predict values and have a better
profit now that we've taken a look at
the visualization of this data we're
going to move on to the next step
instead of just having a pretty picture
we need to generate some hard data some
hard values so let's see what that looks
like we're going to set up our linear
regression model in two steps the first
one is we need to prepare some of our
data so it fits correctly and let's go
ahead and paste this code into our
jupyter notebook and what we're bringing
in is we're going to bring in the
sklearn pre-processing where we're going
to import the label encoder and the one
hot encoder to use the label encoder
we're going to create a variable called
label encoder and set it equal to
capital L label capital E encoder this
creates a class that we can reuse for
transferring the labels back and forth
now about now you should ask what labels
are we talking about let's go take a
look at the data we processed before and
see what I'm talking about here if you
remember when we did the companies dot
head and we printed the top five rows of
data we have our columns going across we
have column 0 which is R and D spending
column one which is Administration
column two which is marketing spending
and column three is State and you'll see
under State we have New York California
Florida now to do a linear regression
model it doesn't know how to process New
York it knows how to process a number so
the first thing we're going to do is
we're going to change that New York
California and Florida and we're going
to change those to numbers that's what
this line of code does here x equals and
then it has the colon comma 3 in
Brackets the first part the colon comma
means that we're going to look at all
the different rows so we're going to
keep them all together but the only row
we're going to edit is the third row and
in there we're going to take the label
coder and we're going to fit and
transform the X also the third row so
we're going to take that third row we're
going to set it equal to a
transformation and that transformation
basically tells it that instead of
having a New York it has a zero or a one
or a two and then finally we need to do
a one hot encoder which equals one hot
in order categorical features equals
three and then we take the X and we go
ahead and do that equal to one hot
encoder fit transform X to array this
final transformation preps our data
Force so it's completely set the way we
need it is just a row of numbers even
though it's not in here let's go ahead
and print X and just take a look at what
this data is doing you'll see you have
an array of arrays and then each array
is a row of numbers and if I go ahead
and just do row zero you'll see I have a
nice organized row of numbers that the
computer now understands we'll go ahead
and take this out there because it
doesn't mean a whole lot to us it's just
a row of numbers
next on setting up our data we have
avoiding dummy variable trap this is
very important why because the computers
automatically transformed our header
into the setup and it's automatically
transformed all these different
variables so when we did the encoder the
encoder created two columns and what we
need to do is just have the one because
it has both the variable and the name
that's what this piece of code does here
let's go ahead and paste this in here
and we have x equals x colon comma one
colon all this is doing is removing that
one extra column we put in there when we
did our one hot encoder and our label
encoding let's go ahead and run that and
now we get to create our linear
regression model and let's see what that
looks like here and we're going to do
that in two steps the first step is
going to be in splitting the data now
whenever we create a predictive model of
data we always want to split it up so we
have a training set and we have a
testing set that's very important
otherwise we'd be very unethical without
testing it to see how good our fit is
and then we'll go ahead and create our
multiple linear regression model and
train it and set it up let's go ahead
and paste this next piece of code in
here and I'll go ahead and shrink it
down a size or two so it all fits on one
line so from the sklearn module
selection we're going to import train
test split and you'll see that we've
created four completely different
variables we have capital x train
capital X test smaller case y train
smaller case y test that is the standard
way that they usually reference these
when we're doing different models
usually see that a capital x and you see
the train and the test and the lowercase
Y what this is is X is our data going in
that's our RND spin our Administration
our marketing and then Y which we're
training is the answer that's the profit
because we want to know the profit of an
unknown entity so that's what we're
going to shoot for in this tutorial the
next part train test split we take X and
we take y we've already created those X
has the columns with the data in it and
Y has a column with profit in it and
then we're going to set the test size
equals 0.2 that basically means 20
percent so twenty percent of the rows
are going to be tested we're going to
put them off to the side so since we're
using a thousand lines of data that
means that 200 of those lines we're
going to hold off to the side to test
for later and then the random State
equals zero we're going to randomize
which ones it picks to hold off to the
side we'll go ahead and run this it's
not overly exciting so setting up our
variables but the next step is the next
step we actually create our linear
regression model now that we got to the
linear regression model we get that next
piece of the puzzle let's go ahead and
put that code in there and walk through
it so here we go we're going to paste it
in there and let's go ahead and since
this is a shorter line of code let's
zoom up there so we can get a good look
and we have from the sklearn dot linear
underscore model we're going to import
linear regression now I don't know if
you recall from earlier when we were
doing all the math let's go ahead and
flip back there and take a look at that
do you remember this or we had this long
formula on the bottom and we were doing
all this summarization and then we also
looked at setting it up with the
different lines and then we also looked
all the way down to multiple linear
regression where we're adding all those
formulas together all of that is wrapped
up in this one section so what's going
on here is I'm going to create a
variable called regressor and the
regressor equals the linear regression
that's a linear regression model that
has all that math built in so we don't
have to have it all memorized or have to
compute it individually and then we do
the regressor.fet in this case we do X
train and Y train because we're using
the training data X being the data n and
y being profit what we're looking at and
this does all that math for us so within
one click and one line we've created the
whole linear regression model and we fit
the data to the linear regression model
and you can see that when I run the
regressor it gives an output linear
regression it says copy x equals True
Fit intercept equals true in jobs equal
one normalize equals false it's just
giving you some general information on
what's going on with that regressor
model now that we've created our linear
regression model let's go ahead and use
it and if you remember we kept a bunch
of data aside so we're going to do a why
predict variable and we're going to put
in the X test and let's see what that
looks like scroll up a little bit paste
that in here predicting the test set
results so here we have y predict equals
regressor dot predict X test going in
and this gives us y predict now because
I'm in Jupiter in line I can just put
the variable up there and when I hit the
Run button it'll print that array out I
could have just as easily done print y
predict so if you're in a different IDE
that's not an inline setup like the
Jupiter notebook you can do it this way
print y predict and you'll see that for
the 200 different test variables we kept
off to the side is going to produce 200
answers this is what it says the profit
are for those 200 predictions but let's
don't stop there let's keep going and
take a couple look we're going to take
just a short detail here and calculating
the coefficients and the intercepts this
gives us a quick flash at what's going
on behind the line we're going to take a
short detour here and we're going to be
calculating the coefficient and
intercepts so you can see what those
look like what's really nice about our
regressor we created is it already has a
coefficients for us we can simply just
print regressor dot coefficient
underscore when I run this you'll see
our coefficients here and if we can do
the regressor coefficient we can also do
the regressor intercept and let's run
that and take a look at that this all
came from the multiple regression model
and we'll flip over so you can remember
where this is going into and where it's
coming from you can see the formula down
here where y equals M1 times X1 plus M2
times X2 and so on and so on plus C the
coefficient so these variables fit right
into this formula y equals slope one
times column one variable plus slope two
times column two variable all the way to
the m into the n and x to the N plus C
the coefficient or in this case you have
minus 8.89 to the power of two etc etc
times the First Column and the second
column and the third column and then our
intercept is the minus one zero three
zero zero nine point boy it gets kind of
complicated when you look at it this is
why we don't do this by hand anymore
this is why we have the computer to make
these calculations easy to understand
and calculate now I told you that was a
short detour and we're coming towards
the end of our script as you remember
from the beginning I said if we're going
to divide this information we have to
make sure it's a valid model that this
model works and understand how good it
works so calculating the r squared value
that's what we're going to use to
predict how good our prediction is and
let's take a look at what that looks
like in code and so we're going to use
this from
sklearn.metrix we're going to import R2
score that's the r squared value we're
looking at the error so in the R2 score
we take our y test versus our y predict
y test is the actual values we're
testing that was the one that was given
to us so we know are true the Y predict
of those 200 values is what we think it
was true and when we go ahead and run
this we see we get a
0.9352 that's the R2 score now it's not
exactly a straight percentage so it's
not saying it's 93 percent correct but
you do want that in the upper 90s oh and
higher shows that this is a very valid
prediction based on the R2 score and if
r squared value of 0.91 or 92 as we got
on our model remember it does have a
random generation involved this proves
the model is a good model which means
success yay we successfully trained our
model with certain predictors and
estimated the profit of the companies
using linear regression the Y linear
regression now that we have come this
far I'm planning to take closer look at
our cells so that we can estimate cells
in the future how about we hire a data
scientist you can see our two corporate
individuals looks more like they should
be agents or secret agents someplace
discussing how to better forward their
company and so they're going to come in
and ask the data scientist to come in
good idea this will help us to keep a
constant track of ourselves so why do we
need linear regression let's assume that
we need to predict the number of skiers
based on snowfall so this happens to be
we've kind of jumped one business to the
next we're looking at the skiing
business very popular in a lot of areas
and it's based on snowfall a lot of
times you figure you don't have snow you
don't have skiers but can we actually
use something more specific instead of
look it's snowing and instead of saying
Hey look it's snowing we can actually
start drawing graphs and the graph shows
that with an increase in snowfall the
frequency of skiers also increases so
and there's a pretty direct correlation
if you've ever been up to ski areas when
there's a lot of snowfalls the skiers
all show up because they know it's going
to be better skiing right after word so
it's kind of easy to see why skiers and
snowfall would go together and usually
draws a nice straight line and you can
easily predict how many skiers and that
way you can also predict how many people
you need to service them how many lifts
they have up and running and all the
stuff that goes with running a ski area
thus we see that the number of skiers
are directly proportional to the amount
of snowfall regression models a relation
between a dependent Y and an independent
X variable this is real important to
understand regression because when we
talk about linear regression it's the
basis of almost all our machine learning
algorithms out there and it's usually an
underlying part of the math in our deep
learning so it all starts here with
linear regression and we talk about a
dependent Y and an independent X
variable these are numbers we're usually
talking about floats so we want to have
an actual number value coming out and
that's different than something that's
categorical or we want to know yes or no
true false so regression means we're
looking for a number the independent
variable is known as predictor variable
and dependent variable is known as the
response variable so we have one
predictor variable the amount of
snowfall and one response variable how
many skiers are going to show up and
then we can take this relationship and
it can be expressed as y equals beta
we're going to use the Greek letter beta
and we have beta naught plus beta1 X1
and if you continue out it'd be plus
beta 2 x 2 and so on till the nth degree
in this case snowfall is an independent
variable and skiers is a dependent
variable so we kind of had a little
quick overview let's go ahead and talk a
little bit more about what is linear
regression so we're going to go from y
predicting a number of skiers for
snowfall and we looked at the formula a
little bit but let's look a little bit
closer at what exactly is going on with
linear regression and the question is
going to come up in an interview what is
linear regression linear regression is a
type of statistical analysis that
attempts to show the relationship
between two variables linear regression
creates a predictive model on any data
showing Trends in in data the model is
found by using the least Square method
there are other methods the least Square
method happens to be the most commonly
used out there and we usually start with
the least Square method since it's the
most common and usually works the best
on most models and we're already looking
at how linear regression works but let's
dig deeper into it and let's take a
closer look how linear regression works
I will provide you with a data set which
has rent area other information in it
looks like our secret agents have put on
their casual wear for this one you need
to predict rent accordingly we are given
area and rent here so you can do linear
regression with more variables but we're
just going to look at the area and then
from that try to figure out what the
rent should be we plot the graph and if
you look at it here you can see that the
graph kind of a linear pattern with a
little dip in it so the area seems the
rent seems to be based on the area in
most of our work as data scientists we
usually try to start with a physical
graph if we can so we can actually look
at it and say hey does what I'm fitting
to this graph look right you can solve a
lot of problems that arise by looking at
the graph and saying no that doesn't
look right at all or oh I should be
looking over here for this then we find
the mean of area and rent so the mean
just means average and if you take one
two three four five and add them all
together and divide by in this case
there's five areas you get three and the
rent is two four six five and eight if
you add them all together and divide by
five you get five and we plot the mean
on the graph so you can see right here
here's the mean of the rent and the area
it's kind of a very Central Point which
is what we're looking for the average of
everything in there the best fit line
passes through the mean this is real
important when you're eyeballing it as
humans we can do this fairly easy if
it's a straight line through a bunch of
data it gets more complicated
mathematically when you start adding
multiple variables and instead of a line
you have a curve but for basic linear
regression we're going to draw a line
through the data and the line should go
through the means that's going to be
part of the best fit for that line but
we see there are multiple lines that can
pass through the means so depending on
how you look at it you can kind of
Wiggle the line around back and forth so
we keep moving the line to ensure that
the best fit line has the least squared
distance from the data points and this
is you can see right here residual we
have our data point and then we look at
this distance between them and we square
that distance and that's what they mean
by the least squared distance we want
all those distances to add up to the
smallest amount we can we talk about
that distance we call it the residual it
equals the Y actual minus the Y
predicted very straightforward we're
just looking at the distance you can
accidentally switch these and it'll come
out the same because we're going to
square it but when you're working with
other sets of linear regression you want
to make sure you do the Y axial minus
the Y predicted the value of M and C for
the best fit line Y equals MX plus C can
be calculated using the mentioned
formula and you can see here we have m
equals the number of points that's what
n stands for then we have the sigma the
Greek symbol is there which is a
summation of x times y minus the
summation of x times the summation of Y
over the number of the summation of x
squared minus the summation of x squared
of X all of it squared that can be a
little confusing trying to say that and
then of course your C value is going to
be the summation of Y times the
summation of x squared minus the
summation of x times the summation of x
times y over the total count of the
summation x squared minus the summation
of x squared that's a mouthful normally
we don't worry too much about these
formulas other than to know they're
there now if you're a mathematician you
might go back in there and work on those
and those people who originally started
to put together the different models in
R of course had to know all this math to
build them and had to test it out that's
one of the nice things about R what is
important is that you know about these
formulas so that you know where it's
coming from so if you're using one
linear regression model this is how this
one works there's other linear
regression models based on different
math and so you'd have to be aware when
that math changes and how that changes
the model we find the corresponding
values so in this case if you're going
to break this up and you're building
your own model instead of using the one
in R you would have your rent you would
have your area you would find your rent
squared your area squared and your rent
times area and if we go back one we can
see that that's all the different little
pieces in this model we have x times y
we have x squared we have the sum of X
which is going to be squared we have the
sum of X the sum of Y this is the same
these are all the little pieces in here
that we see for m equals and C equals
and so once we compute all these we have
15 25 55 145 88 very easy to do on a
computer thankfully you could have
millions of these points and it would do
it in a very short period we can then
plug in those values very easily into
this formula and get a final answer and
we'll see that m equals 1.3 and C equals
1.1 and then when we take this for the Y
predicted equals m of I X of I plus C we
can take these and actually run the data
we have so we're going to see how it
predicts so now we find the Y the value
of y predicted so we have our X in and
we want to know what Y what we think y
will be based on our formula we
generated the linear regression formula
and so when we come in here we have our
X we have our actual y then we have our
y predict what we think it's going to be
and then we have we take y minus y
predict and we get those values minus
0.4 it's off by 0.3 this one's off by
one this one's on off by minus 1.3 by
0.4 and we go ahead and square that and
then we can sum that square and average
it out and we'll get a value this is
just a summation down here of Y minus y
predicted square is 3.1 and we call that
the least Square value for this line is
3.1 and we go ahead and divide that by
five so when we plot the Y predict and
this is the best fit line and you can
see that it does a pretty good job going
right through the middle of lines and in
something like rent versus area if
you're trying to figure out how much
rent to charge or how many people are
allowed to be in the area that's going
to work but if you're looking for the
rent value compared to the area this
gives you a good idea based on the area
of what you should rent the place for
it's close enough that in the business
world this would work you're not
Computing something down to the
millimeters or micrometers or Nuclear
Physics we're just charging people and
so if you're off by a couple dollars
it's not a big deal you'll be pretty
close to what you think it's worth and
get the right value for your property
use case predicting the revenue using
linear regression now that you have a
good idea of how linear regression works
and we're kicking back on our lounging
sofa today let's work on a real life
scenario where you have to predict the
revenue so we're going to take a data
set and we'll pull this up in just a
minute we'll have a paid organic social
and revenue there are three attributes
we'll be working on the first one is our
paid traffic so all the traffic through
the advertisement that comes in the
non-paid traffic from search engines so
these are people coming to the website
and are doing so because they did a
search for something specific so it's
pulling it from your website all the
traffic coming from social networking
sites so we want to know what's coming
from Twitter and Facebook and somehow
they've linked into your website and
coming into your marketing area to buy
something and we'll use this to predict
the revenue so we want to know how all
this traffic comes together and how it's
going to affect our cells if the
traffic's coming in we're going to make
use of the multiple linear regression
model so you'll see that this is very
similar to we had before where we had y
equals m times X plus C but instead we
have y equals M1 X1 plus M2 X2 plus m3x3
plus c m is the slope so you have M1 M2
M3 the three different slopes of three
different lines Why is the revenue so
we're only looking for one variable and
remember this is regression so we're
looking for a number X1 is going to be
the paid traffic and of course M1 the
corresponding slope X2 the organic
traffic and X3 the social traffic we
will follow these steps to create the
regression model we'll start by
generating inputs using the CSV files
we'll then import the libraries
splitting the data into train and test
very important whenever you're doing any
kind of data science applying regression
on paid traffic organic traffic social
traffic so we're going to apply our
regression model on them and then we're
going to validate the model that's the
whole reason we split it to a training
and testing is so we can now validate to
see just how good our model is now
before we open up our I always like to
just take a quick look at the data
itself and we're using the rev.csv file
and this is a CS file or comma separated
variable file we'll just open that with
wordpad any kind of text editor would be
nice to show you what's going on and you
can see we have paid organic social and
revenue across the top so those are
titles for your columns and the values
going down and this is the same as what
we saw on the slide just a minute ago
paid organic social and then revenue
from them they probably have it in more
of a spreadsheet than just a word pad
and I'm using the newer version of our
studio which already has a nice layout
automatically opens up with your console
and terminal window down and left you
have your script and we'll run it in
script and then when I run it line by
line in script you'll see it show up on
the console bottom left I could type it
straight into the console and it would
do the same thing and then on the right
we have our environment and under the
environment we'll see plots if you're in
an older version the plots will pop up
and you usually are running just in the
console and then you have to open up a
different window to run the script and
you can run the script from there this
opens up everything at the same time
when you use the new R Studio setup and
the first thing we want to do is we want
to go ahead and generate a variable
we'll call it cells and we want to load
this with our data set and so uh in R we
use the less than minus sign that's the
same as assigned to it's like an arrow
pointing at cells it says whatever it
goes past here is going to be assigned
to cells we want to read in our CSV file
and then I went ahead and fixed the C
ESP file up a little bit when I say the
CSV file I mean the path to it
um and we'll go ahead and just paste
that in there and this is my edited
version and you'll see I took wherever
we had the backward slash I switched it
for a forward slash because a backward
slash is an escape character and
whenever you're programming in just
about any scripting language you want to
do the forward slash instead so like a
good Chef I prep this and copied it into
my clipboard and we can see the full
path here and the full path ends in our
rev.csv file so that's the path on my
machine and then I'm going to run that
and now we have down here you see it
appear right here oh must have an error
in my path it says object rev not found
let me fix that real quick and run it
again and this time it does assign the
cells the data set and then we'll just
type in cells and this is the same as
printing it so if you work in other
languages you'll do like print and then
sales or maybe print sales.head if
you're in pandas in python or something
like that but in R you just type in the
variable we'll run this and you can see
it printed out all those columns so
that's the same thing we just looked at
and it says Max print so it emitted 750
rows so so it has a total of a thousand
rows and we can scroll up here on our
console where the answer came in and if
I scroll up to the top whoops way up to
the top there we go you'll see paid
organic social and revenue so everything
looks good on this and there's a lot of
cool things we can do with it one of the
things we can do is I can summary it so
let's do a summary of cells and we'll
run that and the summary of cells comes
in it tells you your Min first quarter
median mean third quarter Max for paid
organic social breaks it up and you can
actually get kind of a quick view as to
what the data is doing you can take more
time to study this a lot of people look
at this and you can see from the median
the mean that tells you a lot and is
divided into quarters so you have your
first quarter value and your third
quarter setup on there and Max it just
gives you a quick idea what's going on
in the data summary is a really
wonderful tool one of the reasons I like
to jump into R before I might do a major
project in something else or you can run
everything enough and let's take a look
at the head head of cells and let me run
this and you can see it just shows the
head of our data the first six rows in
this case and it starts with one
important to know the other different
systems start with zero and go up R is
one that starts with the first is one
and then if we want to do a plot I'll go
ahead and do a plot cells another really
powerful tool that you can just jump
right into with r one save your data in
here and you'll see that the plot comes
over on the right hand side and what it
does is it Compares them so if I look at
my paid and my organic and you cross a
two you'll see there's a nice line down
the middle big black line where plus the
two together let me just widen this a
little bit so we can see more of it
there we go same thing with paid and
social paid and revenue so each one of
these has a clear connection to each
other so that's a good sign we have a
nice correlation between the data and
you can just eyeball that that's a good
way to jump in and explore your data
rather quickly and see what's going on
so we'll go ahead and I'll put a pound
sign there a hashtag and splitting the
data into training and test data and we
want to split it so that we have
something to work with to train our data
set and when we do our data set you do
this with any data sets you want to make
sure you have a good model and then once
we've trained it we're going to take the
other set of data we pulled off to the
side and we'll test it to see how good
it is if you test it with the training
data it's already got that memorized and
should give you a really good answer in
fact when you get into more advanced
machine learning tools you watch those
very closely you watch your training set
and how it does versus your testing set
and if your training set starts doing
better than your testing set then you're
starting to over train it now that's
more with deep learning and some other
packages that are beyond what we're
working with today but you know this is
important it's very important to
understand that that test and that
training correlate with each other and
gives you an idea what's going on and
make sure that you're set up correctly
and we'll go ahead and set a seed of two
and that's for our random gen generators
so that when we run them you could see
them with just a red there's a ways to
randomize a number you could do like
date and stuff like that but that way we
always use the same random numbers so
we'll seat it with two and then we're
going to need a library in this case
we're going to import the library and we
want to import CA tools and CA tools has
our split function so we're going to be
able to split our data along with many
other tools we're going to need for this
example so they're all built into the ca
tools that's why we need to import that
a lot of times they call them library or
sometimes you hear them referred to as
packages so let's go ahead and run that
line and that brings the library in so
now we can use all those different tools
that are in there and then I'm going to
do a split and we're going to assign to
the split that's going to be our
variable sample split okay so that's one
of the tools we just brought in is to
sample is the actual keyword or the
function word sample.split and we're
going to take our cells and we're going
to go ahead and with split ratio equals
to 0.7 and let's do 0.7 so we make sure
it knows it's a decimal point or float
and what this is saying is that we're
going to take our cells data the
variable we created called cells that
has the data in there and I want to
split it and I'm going to split it so
that 70 of it goes in one side we'll use
that for training and 30 percent will go
into the other side which we'll use then
for testing out our model let me go
ahead and run that and let's hold on one
second got an error there spit is
definitely very different than split I
don't think we want to spit our data out
we which is actually kind of what we're
doing is spitting it out but we want to
split we want to split the data
something get that spelled correctly and
then when I type in Split we can just
run that because it's now a variable
you'll see that it has true false false
true so it generates a number of
interesting different statistics going
across there as far as the way it splits
the data and right here if you have not
used R in a while or if you're new to R
completely that line one that's what
that little one means down there and
then true false false all is true that
means that's how we're looking at the
data we're splitting all those different
pieces of data in line one different
directions and so we now want to create
our train set and we're going to assign
that and when we take it and we assign
to the train set a subset of cells and
then the subset of cells is going to be
based on split equal let me put this in
Brackets true so you can see the values
down here is capital T capital r capital
u capital E so I just want to reflect
that on the train and this is going to
take everything where our split variable
is equal to true and it's going to set
cells equal to that and we'll go ahead
and run that and then we're going to set
our test variable as a subset of cells
and if we assign the true to the train
set then we want to assign the false to
our test set so now we'll have this will
have 30 percent of the variables in it
and Trane will have 70 percent we'll go
ahead and run that so we've now created
both our training set and our test set
and we can just real quickly type in
train hit the run on there and you can
see our train set if we scroll way up to
the top they'll have the column names on
there which should match what we had
before paid organic social and revenue
and then we'll type in test when I hit
run on there that's going to do the same
thing it'll spit out all the test
variables going out so now that we have
the test and train variables we want to
go ahead and create the model and you'll
see this in any of the machine learning
tutorials they always refer to them as
models we're modeling a function of some
kind on the data to fit the data and
then we're going to put the test data
through there to see how well it does
and so we're going to create the
variable called models and I'm going to
assign that LM that is our linear
regression model I love how simplified R
makes it just LM linear regression and
then model M
I guess it dates back because the linear
regression model is like one of the
first major models used so they kept it
easy on there and revenue happens to be
be the main variable that we want to
track so if you remember correctly from
our formula Y is the revenue and then we
have X is our paid traffic X2 organic
traffic and X3 are social traffic so Y
is what we want to predict in here and
then you'll see this notation where we
have our squiggle and the period which
means we're going to match up the
revenue lines with the lines of the data
we're putting in here and then I'll put
comma and then our data equals train and
of course that's the training data that
we created so when I hit the Run
remember we did all the discussion about
all those different functions and
formulas to compute our model and how
that's set up when it comes down to it
we spend all our time setting up our
data and then we hit the Run button on
the single line and our model's been
trained so we now have a trained model
here and we can do a summary of the
model summary is such a wonderful
command because you can do that on r
that works on all kinds of different
things on there oops and of course it
does help if I remember that my model
has a capital N when I run it and you'll
see right right here tells you a little
bit about the model use a summary on
there comes down here it has our
residuals this is all the information on
there as far as like the minimum the
median the Max has all our coefficients
in there if you remember correctly from
our formula let's just go ahead and
switch back over to that we have M1 X1
M2 X2 M3 X3 plus C well this right here
here's our intercept and then we have
our different values for each of these
so you have our intercept our paid
organic and social and then it also
shows us error and information on the
error and one of the really nice things
about when you're working with r you can
come down here and you see where we have
our Stars down here and it says three
stars really good two stars maybe one
star probably no correlation and we can
see with all of these it has three stars
on them so out of three stars we get
three stars on all these there's no four
stars four stars would mean that to have
the exact same data going in as coming
out and then if we're going to do this
we want to actually run a prediction on
here and that's that we saved our test
data for so let's come down here we'll
do our prediction we'll take this
variable and we'll sign it predict model
remember the predict comes from when we
imported that package the ca tools
that's all part of the ca Tools in there
so we're going to predict we're going to
use the model and then we're going to
use our test data pretty straightforward
quick and easy we'll run this and then
if we go ahead and type in the predict
it'll print out what's in that variable
and you'll see down here the predicted
values expects to come out it's going to
say our revenue is and it goes through
and it gives it both the line number and
the actual Revenue value so that's quick
and easy boy we got to prediction really
fast and this is also how you would do
it if you had new data coming in after
this you could predict the revenue based
on these other factors so now that we
have a training model which or we train
the data with our training data or we
trained the model with our training data
and we've done a prediction on our model
with our test data we want to look this
up and we took a quick glance from our
training thing our training said it
trained really well but that's not the
final word on it the final word is going
to be comparing it so we want to go
ahead and do comparing predicted versus
actual values what I'm going to do is
I'm going to do a plot and I'm going to
do our test and we're going to do test
Revenue DOT type equals and we can put
this in as a type type 1 and then or L
and then we have lty equals 1.8 and
we're going to set up for column blue
that's a lot of stuff in there let's go
ahead and just run that so we can see
what that looks like and what's that's
doing it's going to generate this nice
graph we see on the right there's our
graph you can see the data comes up and
down we're plotting the prediction on
there so this is the values we predicted
and then let's go ahead and do lines and
I actually did this backwards so let me
try that again and we'll start with the
red one we're going to do the first one
in red and I want to start with the
actual test Revenue so here's our test
revenue and we'll go ahead and run this
and it's we have a red plot over here in
red go ahead and take a look at that and
pull that over you can see how that
looks goes up and down hard to track
there and then we're going to do a
couple things here we'll plot our test
Revenue
and then we'll make it a little prettier
though it's kind of hard to say see the
way I was crunched up here on the right
as far as size and sizing and everything
but we'll go ahead and have our columns
in blue and run our prediction on there
too you can see they overlap the two
graphs so we have our test revenue and
our prediction and then finally what I
started with is we'll go ahead and plot
the prediction fully on the bottom and
run that and if you look over here on
the graph we put the blue lines over the
red lines and so you'll see a couple
spots where there's red underneath there
but for the most part our prediction is
pretty right on so it looks really tight
looks like a good set of predictions for
what we're working on and this is where
we're looking at the slide right before
we started diving into the r Studio we
can see in the slide here here's the red
this little bit better spread out than
what I have on my screen for my R studio
and the graph shows a predicted Revenue
we see that the two lines are very close
so again they're tight it's right on
this is what we're looking for in our
prediction model but it's not good
enough just having a graph you always do
both and the reason we do both is you
want to have a visual of it because
sometimes you look at these you get to
the graph you're like oh my gosh what is
that and then sometimes you look at the
graph you go that's right on how come my
accuracy doesn't look right and you
realize that your accuracy might be off
or you're plotting it incorrectly so
let's go ahead and look up the accuracy
and we'll use rmsc that's going to be
the variable name we're going to give it
and sqrt the square root of the mean and
mean just means average and then we want
prediction minus sales revenue and then
we're going to take this whole thing and
we're going to square it so what we've
got here is we're going to go through
let's just explain this formula we're
using is I'm going to look at the what I
predict it for to be and what the actual
cells what's our prediction versus our
sales in comparison to the revenue and
when we compare those two we're going to
find the average and then I'm going or
we're going to square each one of those
values and then we're going to average
the square and then find the square root
of that and that's quite a mouthful the
reason we do it this way the reason we
Square the value and then we find the
means is to generate an answer based on
doesn't matter whether it's plus or
minus there's a lot of other formulas
you can use there to check your accuracy
and all kinds of other things you can do
but a quick straightforward way of doing
is just like this and then let's go
ahead and run this
and then we type in the rmsc and they'll
give us an actual printed value out
let's just see what that looks like and
so we have
866.6338 for our accuracy and so we look
at the
866.63 and we compare that to say 50
000. that's pretty close that's that's
actually a pretty good accuracy given
this model takes a little bit more when
you're playing with accuracies and start
dividing out other different aspects of
it to get something you can communicate
better with but you always start with
the square root means that's always a
good place to start there's no better
time to train yourself in the exciting
field of machine learning if you're
looking for a course that goes
everything from the fundamentals to
Advanced Techniques like machine
learning algorithm development and
unsupervised learning look no further
than postgraduate programming and
machine learning in partnership with IBM
this a and ml course because the latest
tools and Technologies from the AI
ecosystem and features master classes by
Caltech faculty and IBM experts
hackathons and ask me anything sessions
this program showcases Celtic ctm is
excellence and IBM's industry progress
the artificial intelligence course
because key Concepts like statistics
data science with python machine
learning deep learning NLP and
reinforcement learning through an
Interactive Learning model with live
sessions enroll now analog exciting a
and ml opportunities the course link is
mentioned in the description box below
what is logistic regression let's say we
have to build a predictive model or a
machine learning model to predict
whether the passengers of the Titanic
ship have survived or not the Shipwreck
so how do we do that so we use logistic
regression to build a model for this how
do we use logistic regression so we have
the information about the passengers
their ID whether they have survived or
not their class and name and so on and
so forth and we use this information
where we already know whether the person
has survived or not that is the labeled
information and we help the system to
train based on this information with
based on this labeled data this is known
as label data and during the process of
building the model we probably will
remove some of the non-essential
parameters or attributes here we only
take those attributes which are really
required to make these predictions and
once we train the model we run new data
through it whereby the model will
predict whether the passenger has
survived or not let's start with what is
supervised learning supervised learning
is one of the two main types of machine
learning methods here we use what is
known as labeled data to help the system
learn this is very similar to how we
human beings learn so let's say you want
to teach a child to recognize an apple
how do we do that we never tell the
child okay this is an apple has a
certain diameter on the top a certain
diameter at the bottom and this has a
certain RGB color no we just show an
apple to the child and tell the child
this is Apple and then next time when we
show an apple child immediately
recognizes yes this is an app supervised
learning works very similar on the
similar lines so where does logistic
regression fit into the overall machine
learning process machine learning is
divided into two types mainly two types
there is a third one called
reinforcement learning but we will not
talk about that right now so one is
supervised learning and the other is
unsupervised learning unsupervised
learning uses techniques like clustering
and Association and supervised learning
users techniques like classification and
regression now supervised learning is
used when you have labeled data you have
historical data then you use supervised
learning when you don't have labeled
data then you used unsupervised learning
yes it supervised learning there are two
types of techniques that are used
classification and regression based on
what is the kind of problem we have
solved let's say we want to take the
data and classify it it could be binary
classification like a zero or a one an
example of classification we have just
seen whether the passenger has survived
or not survived like a zero or one that
is known as binary classification
regression on the other hand is you need
to predict a value what is known as a
continuous value classification is for
discrete values regression is for
continuous value so let's say you want
to predict the share price or you want
to predict the temperature that will be
there what will be the temperature
tomorrow that is where you use
regression whereas classification are
discrete values is will the customer buy
the product or will not buy the product
will you get a promotion or you will not
get a promotion I hope you're getting
the idea or it could be multi-class
classification as well let's say you
want to build an image classification
model so the image classification model
would take an image as an input and
classify into multiple classes whether
this image is of a cat or a dog or an
elephant or a tiger so there are
multiple classes so not necessarily
binary classification so that is known
as multi-class classification
are going to focus on classification
because logistic regression is one of
the algorithms used for classification
now the name may be a little confusing
in fact whenever people come across
logistic regression it always causes
confusion because the name has
regression in it but we are actually
using this for performing classification
okay so yes it is logistic regression
but it is used for classification and in
case you are wondering is there
something similar for regression yes for
regression we have linear regression
keep that in mind so linear regression
is used for regression logistic
regression is used for classification so
in this video we are going to focus on
supervised learning and within
supervised learning we are going to
focus on classification and then within
classification we are going to focus on
logistic regression algorithm so first
of all classification so what are the
various algorithms available for
performing classification the first one
is decision tree there are of course
multiple algorithms but here we will
talk about a few addition trees are
quite popular and very easy to
understand and therefore they use for
classification then we have K nearest
neighbors this is another algorithm for
performing classification and then there
is logistic regression and this is what
we are going to focus on in this video
and we are going to go into little bit
of details about logistic regression
aspiring AIML engineer then there is no
better time to train yourself in the
exciting field of AI if you are looking
for a course that covers everything from
fundamental to Advanced Techniques then
accelerate your in AI animal with our
comprehensive postgraduate program in Ai
and machine learning so why wait enroll
now and unlock exciting AIML
opportunities the link is in the
description box below face detection
system it is a form of biometric
recognition a method for identifying or
confirming someone's identity by
glancing at their face is called facial
recognition people can be identified by
securing a match on facial ID using this
technique real-time visuals videos and
photos can be the sources to run face
detection this technology is mostly
employed in security and law enforcement
opencv is the best technology to create
it a python package called opencv is
made specifically to address computer
vision jobs computer vision is a process
used in the processing of images by
computers it is concerned with the
in-depth comprehension of the digital
photos or films it is necessary to
automate operations that can be
performed by human visual systems
therefore a computer should be able to
identify items like a statue or a
Lamppost or even the face of a human
being
second one is chatbot it is the best
idea if you have chosen chatbot as your
project topic this will make your resume
more attractive in case you are looking
for a job an oracle survey suggests that
80 percent of the businesses uses
chatbot you can use Python Java Ruby C
plus plus or PHP as a programming
language to develop a chatbot designing
and building NLP chatbots that accept
speech and Text data is made easier by
dialog flow you can go through many
projects to get the rough idea there are
many platforms which will help you to
build a chatbot regardless of how
excellent your chatbot is there is
always room for development the finest
chatbot developers constantly enhance
their Bots over the time using Ai and
machine learning social media
recommendation system the rise of web
services like Netflix Amazon and YouTube
has increased the use of recommender
systems in our daily lives they are
algorithms that insist users in finding
information that is pertinent to them
recommender systems are important in
some forms since they can generate a lot
of income or allow you to set yourself
apart from rivals in order to provide
recommendations it evaluates the
relationship between the user and the
object as well as the palace between
users and positions coming to predicting
stock this application is widely
applicable everywhere as AI career
aspirants one will love to develop stock
prediction applications as it is full
this project that would be ideal for
students who want to work in the finance
industry because it it can provide I
repeat because it can provide them a
better understanding of various aspects
of the field coming to medical diagnosis
this project is advantageous from a
medical standpoint AI projects can be
created to detect heart-based diseases
and also detect cancer it is intended to
offer patients with heart illness online
medical advice and guidance after
processing the data this system will
search the database for any illnesses
that might be connected to the given
details using data mining techniques
this intelligent system determines the
disease that the patient's information
most closely resembles
based on the system diagnosis losers can
then speak with qualified medical
professionals users of the system can
also view information about various
doctors coming to an important project
that is search engine search engines are
utilized by all we look for information
on the greatest product to buy a nice
area to hang out or solutions to any
questions we have NLP is quite
significant in modern search engines
because a lot of language processing
takes place there python is the widely
used language to develop any search
engine search engine is mainly confined
with lots and lots of data it is helpful
for any AI career as parents next is
virtual assistants here the challenge is
to build a virtual assistant to assist
user why do you need virtual assistant
in your devices when you are building
your own it is also interesting for a ml
developer to build a virtual assistant
it involves NLP and data mining voice
based virtual assistants are popular
today because they make life easier for
users NLP is utilized to comprehend
human language in order to construct
this system when a voice command is
received the system will translate it
into machine language and store the
commands in its database hate speech
detection in Social social media
automated hate speech detection is a
crucial weapon in the fight against hate
speech propagation especially on social
media for the job many techniques have
been developed including a recent
explosion of deep learning based system
for the objective of detecting hate
speech a number of techniques have been
investigated including conventional
classifiers classifiers based on deep
learning and combination of both of them
on the other hand a number of data set
benchmarks including Twitter sentiment
analysis have been introduced and made
available for the evolution of the
performance of these algorithms and the
last one is predicting house price you
will need to estimate the sale price of
a brand new home in any place for this
assignment the data set for this project
includes information on the cost of
homes in various City neighborhoods the
UCI machine learning repository is the
place where you may find the data set
needed for This research you will also
receive other data set with information
on the age of the population the city's
crime rate and the location of
non-retail Enterprises in addition to
the pricing of various residences it's
an excellent project to test your
knowledge if you are a newbie popular
market research projects that the market
for artificial intelligence will grow
from 59.7 billion dollars in 2021 to
422.4 billion dollars in 2028 artificial
intelligence Automation and Robotics are
disrupting almost every business
companies that don't invest in AI
Services risk becoming obsolete whether
in machine learning smart applications
Appliance digital assistants or
autonomous vehicles
numerous companies stand to benefit from
AI but a handful of them have proven to
be the game changers for 2023 and Beyond
so hey everyone you are already watching
simply learn and here we are with the
list of top 10 AI companies in 2023
if you love watching videos like these
do hit the Subscribe button to never
miss an update from Simply learn so
let's explore and learn about them one
by one starting with the 10th position
which is uipath robotic process
automation or RPA is a technology
developed by uipath that helps
businesses to boost productivity and
reduce cost by automating time consuming
and repetitive operations software
robots can be equipped with uipath AI
Technologies to carry out duties
including reading documents and emails
interpreting language and visual cues
and comprehending the content and the
intent of the communications the RPA
Market is estimated to be worth 38
billion and uipath offers distinct
advantages over the competitors thanks
to its rate and computer vision
technology and wide range of Bot
Technologies in the ninth position we
have Diamond trace the surface is
offered by dynatories include officer
availability and infrastructure
monitoring the Davis AI engine developed
by the business can analyze 368 trillion
dependencies each second Davis can
quickly locate problems in a company's
digital ecosystem explain what went
wrong and evaluate and rate likely
commercial ramifications the company
estimated a market worth
285.42 million and is poised to grow
Revenue by roughly 20 annually
throughout at least 2025 then at the
eighth position we have talented
Technologies data analytics software
startup talented Technologies uses AI to
analyze data according to revenue and
market share palantir was ranked as the
two AI software platform globally by IDC
in September 2022 the United States
intelligence and defense Industries
account for a sizeable portion of
volunteers Revenue the business just won
a new 85.1 million contract from the US
Army Marshall command to assist with the
developing Ai and machine learning
Technologies to enhance equipment
reliability improve predictive
maintenance and improve Supply chains
balance deliver revenues closer to the
higher end of analysis estimates roughly
2.5 billion in 2023 then and the seventh
position is workday workday is a
provider of cloud-based applications
with an emphasis on human resources
management with the systems of workplace
distinctive AI based optimization engine
businesses can manage challenges with
hiring and Staffing fluctuation labor
demand shift scheduling and prioritizing
and more
in April 2022 workday Incorporated
Barrister and AI powered virtual
assistant from espressive into their
platform workday is Raising 2023 markets
Worth to almost 5.53 billion
representing year-over-year growth of 22
percent now in the sixth position we
have intuitive surgical The DaVinci
surgical system offered by intuitive
surgical performs minimally invasive
procedures using Cutting Edge draw
boards and computerized visualization
technology with the help of a big data
and AI in YouTube is developing tools
that will help surgeons by improving
their training and offering them
real-time Direction despite the fact
that the DaVinci surgical system has
been approved by usfda for 22 years
intuitive reported a 13 percent
year-over-year increase is installed in
the system most recent quarter the
global intuitive surgical Market is
projected to reach 6.5 billion dollars
by 2023. moving towards the fifth
position we have IBM for years IBM has
been developing strategies to use its AI
supercomputer to alter the legal banking
academic and Healthcare Industries IBM's
clients harness the power of AI to stay
current on average changing regulations
by providing end-to-end risk and
compliance management IBM continues to
dominate the market for the other
breakthroughs in Ai and its Auto Ai and
auto email products can help data
scientists build and improve Ai and
machine learning models the market worth
of IBM in 2023 will range from 14.4
billion to 16 billion following that in
the fourth position is nvidium high-end
chipmaker Nvidia provides the
significant computing power needed for
advanced AI applications in reality one
of the world's fastest supercomputers
Leonardo is powered by Nvidia Graphics
processing units the parent company of
Facebook meta platforms is building the
biggest artificial intelligence
supercomputer in the world meta also
owns nvidia's Quantum in fiber and
networking system and 6080 a 100 nvda
Graphics processing processors Nvidia is
a significant supplier for fast growing
Industries like high-end gaming business
Graphics cloud computing artificial
intelligence and advanced automative
technology nvidia's outlook for 2023
revenue is expected to be around 6
billion here comes the top three in the
list and in the third position we have
Amazon AI is integrated into every
aspect of Amazon's business including
e-commerce search engines targeted
advertising and Amazon web services
Amazon Alexa one of the most popular
virtual assistant is already present in
many American Homes Amazon said in
August that it would pay 1.7 billion to
acquire robot scored RBT a maker of Home
robots this section can allow Amazon to
boost the use of AI in household
worldwide Amazon expects a 491 billion
Market worth between 2023 and 2027. in
the second position is alphabet alphabet
the company that owns Google and YouTube
uses Ai and Automation in practically
every part of its business including ad
pricing Gmail spam filters and content
promotion in addition it is the parent
company of the autonomous car
manufacturer waymo and the AI software
business deepmind which created history
in 2022 when it became the first
completely autonomous commercial taxi
service to operate on public routes
the market worth of alphabet in 2023
will be around 70 billion dollars and
the first position on the list is
Microsoft in 2020 Microsoft announced
the construction of a new supercomputer
hosted on Azure Microsoft's cloud
computing Network the supercomputer was
created in collaboration with open AI to
train AI models producing substantial AI
models and related infrastructure for
programmers and other businesses in
October Microsoft released Microsoft
designer a graphic design tool that
makes original social media post
invitations and other Graphics using AI
technology Microsoft the tech giant is
expected to earn a market worth of 49.73
billion and with that we have come to
the end of this list of the top 10 a
artificial intelligence companies of
2023 or
currently in recent recently the surge
in jobs related to AI is legitimate due
to its widespread involvement in crucial
Fields according to Indy the pay range
for jobs involving artificial
intelligence is between 160 thousand
dollars to three thousand fifty thousand
dollars and can go even higher so so we
have come up with a list of leading
career opportunities in artificial
intelligence along with companies hiring
for those roles but before we begin here
is a question for you who do you think
is currently leading the AI Market let
us know in the comment section below so
without any further delay let's get
started starting with our list we have
robotics engineer an engineer in
robotics create prototypes constructs
and test machines and updates the
software that manages them additionally
they investigate the most affordable and
secure way to make their robotic system
aspirin should have a bachelor degree in
computer science and pursue a career in
robotics with additional training or
certification in automation is
advantages robotics engineers are in
high demand with 9000 plus job openings
in India and 8 000 plus openings in the
US top companies like Amazon Bosch and
flybase are hiring robotics engineers
but salaries as high as hundred sixty
thousand dollars in the US and rupees 27
lakhs in India next up on our list we
have product manager the role of a
product manager is to recognize and
express user requirements market
research and creating competitive
evaluations and also creating a
product's vision and putting emphasis on
a product strengths and qualities
freshers cannot join as a product
manager it requires basic experience of
two to three years in the field of
product and software development
according to indeed.com an average of
2000 plus jobs are currently available
in India and 20 000 plus job vacancies
are there in the US but top companies
hiring are Tesla Amazon PCS sprinkler
cognizant Etc with a salary as high as
160 000 per year in the US and rupees 20
lakhs per annum in India up next we have
data scientists they mainly deal with
lots of data extraction of Knowledge
from all collected data is the subject
matter of data science it was also voted
the sexiest job of the 21st century good
news is there is no need for any special
degree as a data scientist you need to
have knowledge of machine learning
programming in python or Java and
mathematical modeling being a fresher
you can join as a data scientist too
data scientists are in demand with 17
000 plus vacancies in the US and 3000
plus vacancies in India and big
businesses like accent enter TCS IBM
Google JP Morgan Deloitte Bank of
America recruiting data employees with
salary going as high as two hundred
thousand dollars per year in the US and
rupees 15 lakhs per annum in India
moving forward in our list we have ai
data analyst data mining data cleaning
data interpretation are the three main
tasks of an AI data analyst data
cleaning allows for the Gathering of the
necessary information for data analysis
and AI data analyst make inferences from
the data using statisticals tools and
techniques you need a bachelor degree in
computer science or mathematics to work
as an AI data analyst to get this job
you must have a thorough understanding
of regression and be able to use Ms
Excel according to indeed.com there are
currently 700 plus AI data analyst jobs
available in the United States and 16
000 plus job vacancies in India with top
companies like Accenture IB am we Pro
TCS and capgemini recruiting them and
salary is going as high as 100 000
dollars per year in the US and rupees
8.5 lakhs per annum in India the next
job opportunity in AI is business
intelligence engineer a business
intelligence developer's main duty is to
take both business ends and AI into
account they evaluate complex data sets
to identify various business Trends they
assist in boosting a company's earnings
by planning creating and sustaining
business intelligence solutions to
become a business intelligence engineer
you are required to have a bachelor
degree in mathematics and computer
science according to indeed.com there
are 8 000 plus job available in India
and 5000 plus job vacancies in United
States companies hiring are Amazon
Development Center IBM AWS Etc with this
salary going as high as hundred thousand
dollars per year in the USA and rupees
15 lakhs per year in in India coming to
the top three jobs available in AI at
number 3 we have machine learning
engineer artificial intelligence is
known to include machine learning it
runs simulations using the varied data
provided and produces precise results
they are constantly in demand from the
businesses and their position seldom
goes unfilled they handle enormous
amount of data and have exceptional data
management skills the ability to code
use computers and understand mathematics
a requirement for success as a machine
learning engineer a master's degree in
computer science or mathematics is
highly preferred the necessary
technological Stacks include python are
scalar and Java a deep understanding of
neural networks deep learning and
machine learning algorithm is very
helpful coming to job opportunities
lastdoor.com predicts 13 000 plus job
vacancies in the US and 27 000 plus jobs
available in India with with companies
like mathwork Google Amazon Microsoft
Azure IBM Etc hiring them with salary
going as high as 150 000 per annum in
the US and rupees 10 lakhs per annum in
India coming at runner-up position we
have data architect data Architects are
it Specialists who utilize their
knowledge of computer science and
database architecture to assist and
analyze an organization's data
infrastructure fresher graduates cannot
become data Architects a bachelor degree
in computer science and computer
engineering or related subject is the
absolute minimum requirement to become a
data architect data Architects are in
high demand with 52 000 job vacancies in
the United States and 7000 plus jobs in
India and top companies hiring data
Architects are Amazon IBM Tesla Intel
Wipro with the average salary quite high
as two hundred thousand dollars per year
in the United States and rupees 21 lakhs
per annum in India and Topping our list
of job opportunities in AI is AI
engineer AI Engineers are problem
solvers who create test and use various
artificial intelligence models they
manage the AI infrastructure well to
create practical AI models we use neural
network knowledge and machine learning
methods these models enable one to gain
business insights which AIDS the
organization in making wise business
decisions
ug or PG degree in the field of AI or
computer science is required in addition
to that you can hold certifications from
any reputed organization which will add
up to your resume please check out an
enroll to the AI program by simply learn
in collaboration with Purdue University
the link is provided in the description
below job openings for an AI engineer
are quite high with 35 000 plus job
vacancies in the U.S and 4000 plus jobs
in India and Tech giants like Accenture
TCS IBM Google JP Morgan Beloit Bank of
America recruiting them with salary
going as high as 200 000 dollars per
year in the US and rupees 10 lakhs per
annum in India term generative AI has
emerged seemingly out of nowhere in
recent months with a notable search in
interest according to Google Trends even
within the past year the spike in
curiosity can be attributed to the
introduction of generative models such
as Dali 2 Bard and chargpt however what
does generative AI entail as a part of
our introductory series on generative AI
this video will provide a comprehensive
overview of a subject starting from the
basics the explanation will cater to all
levels of familiarity ensuring that
viewers gain a better understanding of
how this technology operates and its
growing integration to our daily lives
genitive AI is after all a tool that is
based on artificial intelligence a
professional who will exceeds to switch
careers with AI by learning from the
experts then try giving a short simple
trans postgraduate program in Ai and
machine learning from Purdue University
in collaboration with IBM the link in
the description box should navigate to
the home page where you can find a
complete overview of the program being
offered take action upskill and get
ahead what is generative AI generative
AI is a form of artificial intelligence
processes the capability of to generate
a wide range of content including text
visual audio and synthetic data the
recent excitement surrounding generative
AI stems from the user-friendly
interfaces that allow users to
effortlessly create high quality text
graphics and video within a seconds now
moving forward let's see how does
generative AI Works generative AI begin
a prompt which can take form of text
image video design audio musical notes
or any input that AI system can process
various AI algorithms that generate new
content in response to the given prompt
this content can range from essay and
problem solution to realistic created
using images or audio of a person in the
early stages of generative AI utilizing
the technology involved submitting data
through an API or a complex process
developers need to acquaint themselves
with a specialized tool and writing
application using programming language
like python some of the decent and fully
operational generative AIS are googlebot
open AI chatgpt Microsoft Bing and many
more so now let's discuss chatgpt daily
and part which are the most popular
generative AI interfaces so first is
Dali 2 which was developed using open AI
GPT implementation in 2021
exemplify a multimodal AI application it
has been trained on a vast data set of
images and their corresponding textual
description
Dalai is capable of establishing
connection between various media forms
such as Vision text audio it
specifically links the meaning of words
to visual elements open AI introduced an
enhanced version called Dalai 2 in 2022
which empowers user to generate imagery
in multiple Styles based on their
prompts and the next one is chat GPT in
November 2022 chat GPT an AI power
chatbot built on open AI GPD 3.5
implementation
gain immense popularity worldwide open
AI enable user to interact with and
fine-tune the chatbots text responds
through a chat interface with
interactive feedback unlike earlier
version of GPT that was solely
accessible via an API chargeability
brought a more interactive experience on
March 14 2023 openai release gpt4 charge
GPT integrate the conversational history
with a user making a genuine dialogue
Microsoft impressed by the success of
new charge gbt interface announced a
substantial investment in open Ai and
integrated a version of GPT into its
Bing search engine
and the next one is bad Google bard
Google was also an earlier Fortuner in
advancing Transformer AI techniques for
language processing protein analysis and
other content types it made some of
these modern open source for researchers
but were not made available through a
public interface in response to
Microsoft integration of GPT into being
Google hardly launched a public facing
chatbot name Google bot past debut was
made by an error when the language model
incorrectly claimed that the web
telescope was the first to discover a
planet in a foreign solar system as a
consequences Google stock price suffered
a significant decline meanwhile
Microsoft implementation of chat gbt and
GPT powered system also face criticism
for producing inaccurate result and
displaying erratic behavior in their
early irritation so moving forward let's
see what are the use cases of generative
AI generative AI has brought
applicability and can be employed across
a wide range of use cases to generate
much form of content recent advancement
like GPT have made this technology more
accessible and customizable for various
application some notable use cases for
generative AI are as follows chatbot
implementation generative AI can be
utilized to develop chatbots for
customer service and Technical Support
enhancing interaction with users and
providing efficient assistance the
second one is language dubbing
enhancement and the alarm in the realm
of movies and educational accountant
generative AI can contribute to
improving dubbing in different languages
ensuring accurate and high quality
transition and the third one is content
writing generative AI can assist in
writing email response dating profiles
resumes and term papers offering
valuable support and generating
customized content tailor to specific
requirement and the fourth one is our
generation leveraging generative AI
artists can create photorealistic
artwork in various Styles enabling the
exploration of new artistic expression
and enhancing creativity the fifth one
is product demonstration videos
generative AI can enhance to enhance
product demonstration video making them
more engaging visually appealing and
effective in showcasing product features
and benefits so generative AI
versatility allows you to employ it in
many other application making it a
valuable tool for Content creature
enhancing user experience across diverse
domains so after seeing use cases of
generative AI let's see what are the
benefits of generative AI so generative
AI offers extensive application across
various business domains simplifying
their integration and comprehension of
existing content while also enabling the
automated creation of a new content
developers are actively exploring ways
to leverage generative AI in order to
enhance the optimize existing workflows
and even to reshape workflows entirely
to harness the potential of Technology
fully implementing generative AI can
bring numerous benefits including
automatic content creation generative AI
can automate the manual process of
writing content saving time and but by
generating text or other form of content
the next one is efficient email response
responding to emails can be made more
efficient with generative air reducing
the effort required and improving
response time and the third one is
enhanced technical support generative AI
can improve responses to specific
technical queries providing accurate and
helpful information to users or
customers and the fourth one is
realistic person Generation by
leveraging generative AI it becomes
possible to create realistic
representation of people enabling
applications like virtual characters or
avatars and the fifth one is current
information summarization
generative AI can summarize complex
information into a government narrative
distilling key points and making it
easier to understand and communicate
complex concept the implementation of
generative AI offers a range of
potential benefits seemingly process and
enhancing content Creation in various
areas of business operation so after
seeing advantages of generative AI let's
move forward and see what are the
limitations of generative air
serve as Vivid examples highlighting the
numerous limitation associated with this
technology several challenges arise from
the specific approaches employed to
implement various use case for instance
while a summary of a complex topic May
more reader friendly than explanation
incorporating multiple supporting
sources the ease of readability comes at
the expense of transplant identifying
the information sources so the first one
is when implementing or utilizing a
generative AI application it is
important to consider the following
limitation repeat the first one is lack
of source identification generative AI
does not always provide clear
identification of content Source making
it difficult to trace and verify origin
of the information the second one is
assessment of bias assessing the bias of
original sources use generative AI can
be challenging as it may be difficult to
determine the underlying perspective or
agenda of the data utilized in the
training process the third one is
difficulty in identifying inaccurate
information generative AI can generate
realistic content making identifying
inaccuracy or falsehoods within the
generated output harder and the fourth
one is adaptability to a new
circumstances understanding how to fine
tune generative AI for a new
circumstances or specific context can be
complex requiring careful consideration
and expertise to achieve desired result
and the fifth one is glossing over buys
page it is and hatred generative AI
results May amplify or perpetuate biases
prejudices or hateful content present in
the training data requiring Vigilant
scrutiny to prevent such issues so
awareness of these limitation is crucial
when implementing of utilizing genitive
AI as it helps users and developers
critically evaluate and mitigate
potential risks and challenges
associated with the technology so future
of gender TV furthermore advances in AI
development platforms will contribute to
the excluded progress of research and
development in the realm of generative
AI the development will Encompass
various domains such as text images
videos 3D contact drugs Supply chains
logistic and business processor while
the current Standalone tools are
impressive the true transformative
impact generative AI will realize while
these capabilities are seemingly
integrated into repeat into the existing
tools with regular use hello and welcome
to this video on edge AI for artificial
intelligence if you are interested in
learning
AI is
good for you sji is a New Concept in the
world of AI that refers to devices and
sensors at the edge of the network they
can collect and process data in real
time
this allows for faster more accurate
decision making and greater efficiency
in a variety of applications such as
self-driving Vehicles Smart Homes and
health monitoring so how is how is Agi
different from cloud computing and cloud
computing AI the main difference is the
location where the data is processed LGA
enables devices at the edge of the
network to process data locally without
having to send it to the cloud this can
lead to faster more responsive systems
and can help you preserve bandwidth and
reduce latency in contrast cloud
computing AI processes data in the cloud
where it can assess vast amount of data
and compute resources but also requires
a reliable internet connection and can
be slow as AGI becomes more advanced it
has the potential to transform many
Industries such as Healthcare
Transportation manufacturing and a lot
it can enable new applications such as
autonomous vehicles remote surgery and
real-time monitoring of machines and
equipment while cloud computing AI has
many benefits AGI offers the advantages
of faster decision making reduced
latency and improved efficiency so if
you are interested in learning more
about the future of AI Aji is definitely
a topic worth exploring on that note
hello everyone and welcome to Simply
learn in today's video we'll understand
what Edge Computing is and how it is
different from traditional cloud
computing but before we begin make sure
to subscribe to our channel to stay
updated with all the latest Technologies
and hit that Bell icon to never miss any
updates from us so without any further
delay let's get started but wait if you
want to become an expert in Edge
Computing then look no further than
Caltech postage program in machine
learning offered by simply learn which
is an online program designed to provide
students with a comprehensive
understanding of AI and machine learning
Concepts tools and techniques this
program is created in collaboration with
caltex ctme and IBM and it is designed
to provide Learners with a strong
foundation in Ai and machine learning
Concepts this program covers various
topics such as data science statistics
deep learning computer vision and NLP
and help you gain the right skill set on
various tools such as care as matpatlib
tensorflow Django and many more
furthermore the curriculum is structured
around interactive online classes live
sessions with industry experts and
Hands-On projects so why wait hurry up
enroll now and Caltech postgraduate
program in and machine learning and
create your own successful career link
is added in the description box below so
make sure you check that out so without
any further Ado let's jump directly into
our today's topic so firstly let us
understand what is Edge Computing the
term Edge Computing for AI refers to the
process of running air computations and
processing close to the data source or
Edge devices at the edge of a network as
opposed to relying on centralized
cloud-based servers in order to enable
real-time data analysis pick a response
times and a decreased Reliance on cloud
infrastructure it deploys AI models and
algorithms directly on edge devices or
local servers
here it's Computing typically entails
the deployment of lightweight AI models
designed to use on edge devices with
constrained computational power then
these models are frequently deployed to
the edge after being trained using
cloud-based resources The Edge devices
gather data from their sensors or from
outside sources process the data locally
using the a models that have been
deployed and give prompt responses or
start processes based on the data but
water to the rise of Hai well with rapid
advancement in technology in every
sector and businesses are looking to
increase automation to increase workflow
productivity and security and for that
computer programs must be able to
identify patterns and Carry Out tasks
repeatedly and safely in order to assist
people now the range of tasks that human
perform however covers different
situations that are impossible to fully
describe in quotes and rules because the
world is very unstructured well with the
help of developments in Hai machines and
gadgets can Now function with the
intelligence of human cognition whenever
they may be smart applications with AI
capabilities can learn to carry out the
same tasks under various conditions just
like in real life and here are the three
recent innovations that explain why
using AI models at the edge is on the
rise well first on the list we have
advancement of neural networks now over
the years as you know neural networks
and related AI infrastructure have
advanced unmatured allowing for more
generalized machine learning
capabilities this means organizations
have to gain a deeper understanding on
how to train a models effectively and
deploy them in production at the edge
development in computational
infrastructure now running AI at the
edge requires substantial computational
power the field has witnessed notable
advancements in computational
infrastructure to support AI at the edge
particularly recent strikes in highly
parallel graphic processing units or
gpus and CPUs have enabled efficient
execution of neural networks gpus are
specifically designed to handle complex
parallel computation making them a
suitable choice of processing Ai
workloads and finally widespread usage
of iot devices now the widespread
adoption of Internet of thing devices
has generated vast amounts of data these
devices such as industrial sensors smart
cameras and Robotics provide a rich
source of data that can be utilized for
AI analysis at the edge the availability
of diverse iot devices and their ability
to capture real-time data has
facilitated the deployment of AI models
at the edge but why deploy AI at the
edge what are the benefits of edge
Computing now Edge Computing for AI
addresses the limitations and challenges
associated with conventional Centric AI
methods so here are some of the
advantages which it offers firstly
decreased latency Now by performing AI
processing at the edge there is a
significant reduction in network latency
since data no longer needs to be
transmitted to the cloud and back this
is particularly beneficial for
applications that demand real-time
responses or decision making let's say
like autonomous vehicles or Industrial
Automation secondly real-time data
analysis it's Computing for AI enables
EMA data analysis and inference directly
on the edge devices themselves this is
especially valuable for time sensitive
applications that require real-time
insights or predictions eliminating the
need for Reliance on cloud connectivity
enhance privacy and security well Edge
Computing enhances privacy and security
by keeping data and air processing local
sensitive information can be processed
on the edge devices without being
transmitted to the cloud minimizing the
risk of data breaches and ensuring
compliance with data privacy regulations
next we have bandwidth optimization Edge
Computing reduces the volume of data
that needs to be transmitted to the
cloud sending only relevant or let's say
summarized data now this optimization
minimizes bandwidth requirements reduces
Network cost and even lightens the load
on the cloud infrastructure in total and
finally it offers offline functionality
Edge Computing enables a models to
function even in situation which limited
or no internet connectivity this
capability is crucial for scenarios that
require continuous operation in remote
or disconnected environments such as
certain iot applications or field
deployments so these were some of the
reasons why we need to deploy AI at the
edge and the benefit its offering now
comes the main question how exactly does
Edge Computing works well Edge Computing
is primarily focused on the proximity
and location of data processing and
storage the fundamental principle is
simple and it's not feasible to bring
data to a centralized data center the
alternative is to bring the data center
close to the data now in order to enable
machines to perform tasks like let's say
a visual perception object detection
driving cars understanding speech
speaking walking and emulating other
human skills they need to replicate
human intelligence in a functional
manner so for that AI uses a deep neural
network as a data structure to emulate
human cognition these dnns undergo
training in data centers and are exposed
to numerous examples of specific tasks
or question type along with their
correct answer and once the training is
complete the model advances to become a
inference engine capable of addressing
real world questions now from there on
here's how it typically Works firstly
deployment kind of inference engine now
in AJ deployments the inferencing Gen
which is the component responsible for
making predictions or performing AI
tasks is deployed on local computers or
devices located in device environments
like factories hospitals cars satellites
homes and much more
problem identification and data upload
now while the inference engine operates
at the edge it may encounter situation
where it struggles to provide accurate
predictions or encounter challenging
scenarios in such cases the problematic
data associated with these instances is
commonly identified and applied to a
centralized Cloud structure now from
there on there is a continuous
cloud-based model training now the cloud
infrastructure typically in a data
center receives the problematic data
from Edge devices data scientists and AI
experts can then utilize this data to
refine and train the original a models
further this involves using the clouds
computational resources larger data sets
and collaboration tools for model
training and Improvement now and finally
with the updated model deployed at the
edge after being retrained the AI system
continues to operate gaining new data
and insights from its environment the
Aja model can collect further additional
data which can be periodically uploaded
to the cloud and further training and
continuous Improvement this feedback
loops enjoy that the AGI models become
progressively smarter over time so this
is in a nutshell how Edge Computing for
AI Works hope you've understood well let
us talk some of the use cases of edge
Computing for AI in real world well the
combination of AI iot and Edge Computing
has opened up a multitude of
opportunities for Edge AI
revolutionizing the various aspects of
our daily lives so let's delve into some
key areas where Edge AI is making a
significant impact first on the list we
have Healthcare Hai is enhancing medical
Diagnostics and patient care for
instance by deploying AI algorithms on
medical imaging devices Radiologists can
accurately and efficiently identify and
analyze pathologies wearable devices
with local Edge analytics enable
real-time monitoring of patient data
facilitating any early detection of
anomalies And Timely interventions
next autonomous vehicles Edge air plays
a pivotal role in enabling real-time
navigation and decision making for
autonomous vehicles a algorithms running
on edge devices within Vehicles process
sensor data analyze the environment and
make Split Second decisions to ensure
safe and efficient driving agriculture
AGI is being used to address agriculture
challenges as well such as pollination
autonomous drones equipped with Hai
capabilities can identify and pollinate
plants aiding in crop cultivation and
maximizing yields this application
demonstrates the diverse potential of
Hai Beyond traditional domains next we
have smart home and cities now Edge AI
enhances the functionality and
efficiency of Smart Homes and cities
local processing and Analysis of data
from iot devices enable real-time
automation Energy Management security
surveillance and personalized user
experience hji power system adapt to
individual preferences optimized
resources usage and respond to events in
real time
next we have industrial applications
Edge AI is transforming Industries
thoroughly through real-time monitoring
predictive maintenance and process
optimization Edge devices equipped with
AI algorithms analyze sensor data detect
anomalies and predict equipment failures
reducing downtime and improving
efficiency
next we have security and surveillance
well AJ plays a crucial role in security
and surveillance which Empires real-time
video analytics for security and
surveillance applications Edge devices
with a capabilities can analyze video
feeds locally detect suspicious
activities like theft identify objects
or individuals of interest and Trigger
alerts or responses enhancing security
measures and reducing response times
finally we have personal devices edgeai
is increasingly being integrated into
personal devices such as your
smartphones laptops variables and smart
home assistance this allows for
on-device a processing enabling faster
and more personalized experience without
relying heavily on cloud connectivity
which can support voice recognition
facial recognition among other features
as well well as more businesses and
industries recognize the advantage of
Hai its adoption is rapidly growing the
ability to process data locally enhance
privacy reduce latency and make
real-time decision impasse organizations
in various sectors to enhance operations
deliver better services and improve user
experience so these were some of the
real-time applications of agile and with
that we've come to the end of today's
session on what it's Computing for AIS
in this video we are going to take you
through an interesting AI tool which can
help you in different ways the flare AI
we are going to discuss and this AI can
help you create your own advertisement I
mean if you own a product or if you want
to advertise something then this tool is
the go to option for you and we are
going to see how to use this tool in
this particular video but before we
begin if you enjoy watching these videos
and if you find them interesting then
subscribe to Simply learns YouTube
channel because we bring the best videos
for you daily also hit the Bell icon to
never miss any updates from Simply learn
we all know that AI is expanding at a
very rapid Pace charge GPT is a great
example
so in this time backing up job in this
field is super beneficial because of
course it offers great salary packages
and AI is interesting as we all know
so on that note we present to you the
simply learns post graduate program in
Ai and machine learning in collaboration
with Purdue University boost your career
with this Ai and ml course delivered in
collaboration with Purdue University and
IBM you can learn in-demand skills such
as machine learning deep learning NLP
computer vision reinforcement learning
generative AI prompt engineering chat
GPT and many more you'll receive a
prestigious certificate and ask me
anything session by IBM with five
capstones in different domain using real
data sets you will gain practical
experience as well master classes by
Purdue faculty and IBM experts ensure
top-notch education simply learns job
assist helps you get noticed by Leading
companies so this program covers
statistics python supervised and
unsupervised learning NLP neural
networks computer vision Gans Keras
tensorflow and many more skills so
enroll now and unlock exciting Ai and
machine learning opportunities the link
is mentioned in the description box
below so let's begin with flair AI what
we have to do first is we have to go to
Google and just write here flare
AI fine so this is the first option you
will get click on it flare so this is
the interface of play area the AI design
tool for Branded content so it can help
you with your brand
definitely you will get better reach
because
what usually happens is
we use different tools like Adobe
Photoshop and other tools to just show a
brand item in different ways but with
this AI tool we can use this and it's
not time consuming as well so let's
start what we'll do is we'll write here
create with layer so here you can see we
have a demo a demo video basically so
here you can see we have a product a
perfume bottle and here we have
different items or we can say different
options we can generate we can customize
and that's it just right here click
generate it will generate a beautiful
image for you so let's start or if you
want to watch the video here's the video
so here you can see this image turned
into that so we don't have to do much of
editing everything was done by AI so
let's see how we can do it so we'll
click on create with Flare now continue
with Google
so you will have to login
although it's free to use this AI tool
is completely free so here we are we are
going to click on create new project so
here you can see we have
a box for placing our product here so
let's say we are placing something out
of you fine so here you can see we have
a Starbucks coffee let's place it in the
middle so generated image images will
appear here see here you can see
generated images will appear here it's
written now click on generate what you
want to do so here you can see we have
different templates fine we have this
template we can use this we can use any
of them
so let's use
this one fine
and click on this click on generate
paper cup on a rock surrounded by trees
in front of Canyon and River fine so
here you can see it's still progressing
and now here you can see we have a
coffee mug present over here Starbucks
coffee if I zoom in for you a little bit
so here you can see how nice it's
looking it's not even looking like that
this cup is edited it's looking like
that this cup is actually placed there
so another way if you want to do the
same thing what we have to do is we have
to use Adobe Photoshop we have to use
different tools right but here you can
see how detailed it is we have shadows
for the cup as well not just that but if
you
click here on generate and if you will
find the mirror one you will get to see
the
reflection completely so if I click here
paper cup on a wet surface surrounded by
rain in front of Spotlight and strong
Shadows so it's pretty good we'll copy
it as well we'll need it later on I'll
tell you why we need while we'll need it
so here you can see the
it's good right so you here you can see
and
here you can see we have a image the
paper cup
what it said paper cup on a wet surface
the surface is wet surrounded by rain so
here you can see rain
in front of a spotlight and strong
shadows in front of Spotlight and strong
Shadow so here you can see the shadow of
a
paper cup fine
similarly we can use different tools we
have different elements as well like if
you want to use
for example if you go on humans if you
want to use we have a
hand thing so here you can see if you
want to put it here and if you want to
bring it to the front so here you can
see it's
on a hand so here you can see how we can
use this tool fine so we have a number
of options available here if I if we'll
go to a set so here you can see we have
a perfume bottle as well we'll delete
this one
will use a perfume bottle it's from
Chanel and now what we are going to do
is we are going to delete them as well
now what we are going to do is we are
going to generate something else fine so
now we are going to use the editor so
here you can see we have a product which
is a perfume bottle so we have to edit
the prompt in the form below fine the
product is a perfume bottle then we have
a placement where we want to place it
on a mirror
or here you can see we have different
options so let's say we are using wooden
surface surrounded by
surrounded by let's say flowers fine now
create this image in your mind we have a
perfume bottle which is present on a
wooden surface its placement is on a
wooden surface and it is surrounded by
flowers fine now number of results how
many number of results you want I'll
make it extra strong extra strong color
strength and outline strength just to
show you guys how it looks now click on
generate and wait for few seconds not
even minutes but it will be done in few
seconds here you can see how fast this
AI is so this AI tool is very useful if
you have your own brand if you have your
own products not services but product so
here you can see it's present on a
wooden surface and we have flowers on it
fine so what we'll do is we'll write
here next to
orange fine
generate its total it totally depends on
your creativity how you want to create
your image how you want to present your
brand service or your brand brand
product
so you can see we are done with almost
85 percent we have to wait for few more
seconds not even a minute as I already
mentioned and it will be done so here
you can see it's present on a
wooden surface
and the Orange is not there
basically what we have to do is we have
to go to generate we have to use
something else then
we'll use
elements fine let's see if it works or
not perfume bottle on a wooden surface
next to almonds in front of Spotlight
and strong shadow
okay we are not going to use this
what we are going to do is
nature in the background let's see
how it looks wait for few more seconds
and again it will give you an AI
generated image which will be present on
a wooden surface next to almonds in
front of nature in the background now
here you can see we have a wooden
surface we have almonds present over
here and we have nature behind it wow it
looks it looks fine not that good
so what we'll do next is we'll write
here
circular
glass platform
and we'll write here next to
a mug
we are not going to use jungle we are
going to use orange sunset in the
background maybe it will look better
because sunsets are always beautiful so
let's see how it comes out so here we
have
the output so it's present on a circular
glass platform okay it's fine we have a
mug
okay the mug is not visible
or maybe this is the mug it's
not that good and then we have the
sunset so Sunset is here here you can
see now the image looks real that's the
point it's not something that's that
looks like that it's edited or it's just
cropped from somewhere and put it over
there no it looks real fine right it has
the shadows and all the edges and
saturation it's changed as per the
background so right now the background
is sunset so here you can see the orange
lights here present over here fine
so that's how you can use this tool to
create an advertisement for your brand
product now the next thing is not just
that but it allows you to upload your
own pictures so it's quite interesting
let me just delete all of them
so what you have to do is you have to
download the picture of your product
upload it from here
and we have a product of an iPhone so
here I have this picture
okay so I'll skip this for now because
I'm going to show you if I write here
let's say it's an iPhone
done
now
here you can see we have a product
placed here so here you can see we have
a background right we have blue and
white this base as well
so the first first thing we are going to
do is we are going to click on that we
are going to click on edit now the best
part is we can remove this background
and it turns out to be so good let's
check it out so click on remove
background it will take few seconds to
remove all this from your background and
you will notice something that the
background the edges of the phone
how nicely it has done it so here you
can see there is nothing wrong and every
Edge is perfectly fine right the
background is completely removed now now
what we have to do is we have to
generate a image so we have an iPhone we
want it to be presented as circular
glass
platform we will
golden sparkles in front of
let's remove it and see what else we
have
desert in the background let's try this
generate it and it will again take few
seconds
so are you guys ready to check out an
iPhone present in the desert
so basically the idea of this AI tool is
it saves a lot of time for anyone right
so here you can see
the iPhone is present in a circular
glass platform right
and we have
what else we had
okay we had golden sparkles golden
sparkles are here somewhere
and we have a desert in the background
so desert here you can see we have a
desert
now what we'll do is we'll write here
mirror
and we want it to be present in
water
and droplets
fine so let's try it I haven't tried it
either till now so it will take some
time the iPhone will be placed on water
with some droplets surrounding it and
the background will be okay a mirror so
it looks good right so here you can see
the shadow actually the shadow of the
phone how realistic it looks so this is
how you can use this AI tool and not
just that but you can download your
images
so here you can see click on download
image and done the image is downloaded
and just click you have from this to
this and it totally depends on your
creativity how you want to present your
brand product to an expiring AIML
engineer then there is no better time to
train yourself in the exciting field of
AI if you are looking for a course that
covers everything from fundamental to
Advanced Techniques then accelerate your
career in Ai and ml with our
comprehensive postgraduate program in Ai
and machine learning so why wait enroll
now and unlock exciting AIML
opportunities the link is in the
description box below in today's session
we will go through what is movie
recommendation system after that we will
see how movie recommendation system work
moving forward we will see filtering
strategies for moving recommendation
system and at the end we will see
Hands-On lab demo like how to create
movie recommendation system using python
in detail we already have data set with
us we will perform different function
and Implement a movie recommendation
system using python before we move on to
the programming part let's discuss what
is movie recommendation system actually
is and proceed further for the same
so renting CDs and DVDs reading local TV
listenings watching film strip
projectors or recordings all of this is
a thing of the past today
all of the world's biggest film
collection have been digitized and moved
to the online streaming services like
Netflix HBO or YouTube
these platform can now help us with what
is possibly the most difficult task of
all choosing a movie they have been
enhanced with AI powered capabilities
well that is no longer a concern for you
it is final time for machine learning to
put its skills on display in the modern
cinematic landscape
to create Advanced predictive system for
True movie expert data scientists are
prepared to investigate our behavioral
patterns and those of movies
a movie recommendation system also known
as a movie recommender system uses
machine learning to predict a filter
user fill preferences based on their
prior decision and actions it is an
advanced filtration system that
anticipate the consumer in question
potential like selection for a domain
specific item a movie
so after seeing what is movie
recommendation system let's move forward
and see how movie recommendation system
actually works a movie recommendation
system fundamental idea is a pretty
straightforward every recommender system
primarily consists of two components
users and items user receive more
prediction from the system and the
actual movies are the products filtering
and predicting only the movies that a
matching user is most likely to wish to
see in the main objective of movie
recommendation system the user
information from the system database is
used by the ml algorithm for these
recommendation system
based on information from the past this
data is used to forecast the user in
questions behavior in the future
data should be handled by expert because
it is so crucial to ml projects
including the movie recommendation
system
after seeing how movie recommendation
system works let's see some filtration
strategies for removing recommendation
system
to assist user in finding the most
relevant films movie recommendation
system employ a variety of filtration
techniques and algorithm the
content-based filtering and the
collaborative filtering system
subcategories of the ml algorithm used
for the movie recommendations are the
most well liked ones
filtering based on content or content
based filtering a method of filtering
movies in a movie recommendation system
that makes advantage of the item's data
this information which is taken from the
just one user is quite important in this
case
this technique uses an ml algorithm to
suggest movies that are comparable to
the user's past choices
therefore the information about the
prior movie choices and likes just one
person is used to generate similarity in
content-based filtering
and the second one is collaborative
filtering as the name implies this
filtering techniques is based on the
interaction between the relevant person
and the other user for the best outcomes
the system contrast and compare these
behaviors it combines the film choices
and users patterns of several people
like there are two types of
collaborative filtering algorithm the
first one is collaborative filtering
based on users the goal is to find
patterns in Target users and other
database users like movie preferences
and the second one is collaborative item
based filtering the fundamental idea
behind this is to find comparable
products products like movies that
Target users rate or interact with so
after seeing the filtering strategies
for movie recommendation system so here
is one question for you guys I will give
you one minute for this you can comment
or you can give answer in chat section
so I can see if the answer is given by
you are right or wrong
I'm repeating again so here is one
question for you guys I will give you
one minute exactly one minute for this
you can comment or you can give your
answer in chat section so I can see if
the answers given by you are right or
wrong
so the question is which is the best
language for machine learning
programming
which is the best language for machine
learning the first one is Java the
second one is python the third one is R
language and the fourth one is C plus
plus
so this is the question I am repeating
again which is the best language for
machine learning
so option one is Java second python R
language and C plus plus
so I'm starting timer of one minute just
type your answers in comment section or
in a chat section do let me know your
answers
please I want that everyone should
participate in this and make this live
session interesting
so I am starting timer
oh your time starts now
please guys do let me know your answers
in chat section or in you can comment
down
42 seconds to go
you can comment or you can give your
answer in the chat section so I can see
if the answers given by you are right or
wrong
30 seconds more
which is the best language for machine
learning
you can give your answer chat section or
you can comment
so I can see if the answers given by you
are right or wrong guys come on please I
want that everyone should participate in
this and make this live section
interesting
one guys five second more
one
yep time up
so time is over we will give reply those
who gave correct answer and those who
didn't give correct answer we will give
you a reply with the correct answer
so now let's move to our programming
part to perform movie recommendation
system using python
so first we will open command prompt to
write command to open Jupiter notebook
so we will write Jupiter
notebook press enter
so this is the landing page of Jupiter
notebook and select here new
python file
so this is how jupyter notebook UI look
likes so at first we will import some
major libraries or python which will
help us in mathematical functioning so
so the first one is numpy import
numpy as NP
so number is a python Library used for
working with arrays it also has a
function for working in the domain of
linear algebra and matrices it is an
open source project and you can use it
freely numpy stands for numerical python
so here NPD NP is denoting numpy so we
will import the next Library
both
pandas as
PD
is should be space yup
so
pandas is a software Library written for
the Python programming language for data
manipulation and Analysis in particular
it offers data structures and operation
for manipulating numerical tables and
time series so
so after importing libraries we will
move ahead and import data set so for
importing data set we have to write like
we have two data set with us
let me show you the data set we have two
data set with us
the first one is credits
this one
and the second one is movies one
this one movie is one so don't worry you
can get these data set link in the
description box so let me write
here
credits
let's go data frame equals to PD dot
read
underscore CSV
here you have to give your location of
the data set
edits
dot CSV
the second one is movies
let's go data frame
this is for movie data frame PD dot read
PSP
so here you have to give the movie
location movie data set location movies
dot CSV
okay everything seems good
let me run this
yeah
so then
here PD is for the pandas Library read
is used for reading the data set from
the machine and CSV is used for the type
of file which you want to read so after
this let's write code to see the data
set so we will write here
credits underscore DF
and we will run it so this is our so
this is our credit data set and next one
is movies
underscore
so this is our movie data set
so this is how our board data set look
like so here you can see three dots
this one and here also
this one
so we are unable to see our full data
set like what if we want like full a
4803 rows
so at that case
we can write here
PD Dot
set
underscore option
okay
and here we will write display
dot Max
underscore columns
this
and here we will write none
same for the rows PD dot set
option
display
dot Max
underscore rows
okay
none
let's run this
so now if we will write credits
underscore DF
it is running yeah
so now you can see your full data set
like full credit data set with 4803 rows
or four eight zero two rows because
there is
this is starting from zero that's why so
what about movies data set
okay wait running
it is still running you can see here
so here you can see the full data set
movie data set with 4802 rows
or if you want to see only five top rows
so you can write here credits underscore
DF dot hat
so by this
only five top rows so from head you we
can see our five top rows and if we will
use tail instead of head we can see our
last five rows so here let me do with
the movies one
DF Dot
tail
yeah
so here you can see 4798 row four seven
nine and Del four eight zero two so we
tell we can see our last five rows
so moving forward let's merge the credit
data set to movie data set because if we
will combine them the confusion will be
less and at the end it will be better
for us so we will write here movies
underscore
equals to movies
underscore data frame and credits
underscore DF
on
it
okay T is a small I guess yeah perfect
Titan
so let me do something something like
this
okay
it is saying data frame object is not
callable
edits underscore DF
movies
okay why because
we haven't wrote merge here
now it will work
yeah perfect it's working so data is
merged let's see the number of rows and
column using share function so now we
have only one so movies underscore DF
dot shape
okay let's run it 4809 and 2 3 23 but if
we see here like in movies data set so
in movies data set here here yeah yeah
there are 20 and in here we are four
columns in credit data set
so
like so you will be thinking that's why
not 24 why only 23 columns that is why
on title you can see here on title the
titles in both titles are same you can
see here
both titles are same
in both
okay let me show you like this
okay after Pirates of the Caribbean
Spectra and so on
here you can see after pirates of the
academy Spectra and so on
so that is why on title
written while merging so titles are same
so moving forward let's see our merged
data set
so we will write only movies
underscore data frame dot hat
yeah
so our data is merged you can see
the last cast crew movie ID yeah you can
see here movie ID title are the same
damage cast group okay guys
let me give some more
for the better View
yeah
so you can see all Columns of credit
data set are added to movies one so
moving forward let's see another
function like
movies
underscore DF Dot info
so by this
yes you can see
so by this the data frame information is
printed via the info method the data
includes the total number of columns
their labels data kinds memory use rage
index and the number of cells in each
columns like non-null values note that
info method does indeed print the
information
so here you can see the all the
information is printed
okay
like columns name and the all null
values count and data types to like this
int object and
in which we are working most so after
this let's move forward and select some
main column in which you are working
most so we will write movies
underscore DF equals to movies
underscore DF
B
I tell
comma and another one is overview
okay why
okay here we have to like this yeah
so here we have to write John R
Jonah is complete and we will work on
what keywords keywords are the main
keywords okay keywords then
it will cost
then we will
we will do recommendation with the crew
as well
okay
so by running this let me see our data
again with seven okay okay there is one
error okay this is movie
a movie Radio Journal yeah not index
okay got it got it
why not genre
it's John hurts I guess
what it is it's shown it's
that's why
it's Jonas okay
yeah so let's see our data again with
seven columns so I will write so I will
write here movies underscore DF
dot head
here
so you can see only our we have like
movies ID same title overview joiners
keywords cash and create only
so here you you can see the selected
columns okay so let's move forward and
once again let's see the info again like
movies
underscore TF Dot
invoice come with selected columns and
let's move forward and see how many
missing values are present in particular
column so like the columns is full we
can see here but we don't know about
that four thousand eight zero three
values are filled or not so what we will
do it we will see how many missing
values are present there so
here we will write like movies
underscore DF dot is null
dot sum
not like this
yeah perfect
so the function data frame is null this
one is null dot sum dot sum Returns the
number of missing values in the data set
so here you can see overview have three
missing values
so what we can do is we can write here
movies
underscore DF
DF
Dot
drop n a
this
equals to
true
okay
we will run it with sayings okay words
documents
also true okay fine
and yeah it will not create an issue so
if you sat in place equals to true the
drop any method will modify your data
frame directly that means that if you
set in place equals to true the drop any
will drop all missing values from your
original data set let's move forward and
see
movies
underscore DF
Dot
duplicated
so the duplicate method returns a series
with true on false
values that describe which rows in the
data frame are duplicated or not use the
subset parameter to specify if any
column should not be considered when
looking for duplicates
so
here let me run this first
so here we are we are getting 0. y 0 so
if you are like thinking there is no
true or false return so if you write it
without sum like if I will write it
without some
okay let me copy from here yeah and I
will run this so
here you can see
false false false in whole data set
so some will combine them and return you
a value at the end zero represent false
itself
so we need to not need this so we will
write something else
so moving forward let me write First
movies
underscore TF dot I location
0
Dot johnnets
let me run this
so the I log function this one ilock
function
first let me do something like this
it will go up okay huh
Okay so
from ilock function in Python is defined
in the pandas module that helps us to
select a specific row or column from the
data set
using the ilock method in Python we can
easily retrieve any particular value
from a row or column by using index
value so here zeroth position line is
coming
which is here you can see
so name action like name action name
Adventure name fantasy this PSI function
this one science fiction yeah so this is
because I am giving here Jonah that is
why you can see here
see ID 28 name action name something
something like that okay
so
let's import something called ASG
abstract Syntax for tree
so this is one of the major Library
import AST
let me run this import is a class
defined is the AST module that is used
to express the import statement in
python in the form of abstract syntax
tree so
so an abstract syntax tree or just
syntax tree is a tree representation of
the of the abstract syntactic structure
of text written in a formal language
each node of the trade denotes a
construct occurring in the text
so let's convert some like literal to
object and append them so here I will
write Def
convert
obj object
like l
equals to
blank array
for I in
St Dot
control
bit
Which object
okay
l dot append
return
here we are converting is like here is a
convert is a function and L is the array
to append by using for Loop we can
append them to name so let me write code
then I will explain like what is
happening so let me write full code so
movies
underscore TF
donors
okay
because your movies
Donuts
and then dot apply
what
so then movies underscore TF
then I will write keywords
let's do movies
underscore DF
keywords
bye
score DF Dot
so if we will see our old data set in
that like we will see old data set in
that Joiner and that's keyword this
keyword
apps ID name and so on like ID that name
like this type of things so it will
create a message retrieving them so by
using AST Library we just convert them
to the normal one like title so got it
guys so I hope you guys understand till
here if you have any question or any
query regarding any code or question
just put as in comment our team will
shortly provide you the correct solution
attributing again I hope you guys
understand till here if you have any
type of questions regarding any code or
something
so just put as in comments our team will
shortly provide you the correct solution
so moving forward let's convert cash to
and like same as previous way like like
this only
so what we will do here we will write
def
convert
pm
here I am using
so l equals to
counter equals to zero
St
dot literal
if counter
does not
equals to 3
then
l dot
a DOT
dot append okay then here I have to
write I
to name
counter
equals to 1.
if you want to write like count as
equals to counter plus one it is like
both the same
else
like
done
l
so let me run this let me run this
okay so after this a small code we have
to assign the values like
we are doing it for castner so movies
okay moves
let's go DF then cast
let's show movies
underscore DF
asked
Dot
lie
convert
everything seems good
so let's see the changes are visible or
not so we will write here movies
underscore DF
dot hat
you can ignore this like this is nothing
so here you can see cast is also same
like keyword and journal so like let's
do for the creo2
so like we are converting you can say in
a structured way
so let's do for the crew one two so let
me put some
yeah
so here we will add depth like fetch
which is nothing like
a function name as director
obj
colon l equals to
or i n s t Dot literal
obj
if
I
talk
equals to
we can hit director
so then
l dot append
l dot append
um
dot append to the same name
but
return
okay capital l
so we have to again write that movies
equals to movies
in
crew
lie
h
just remember fetch director is a
function name let's see changes
so here I have to write movies then
press enter
so yeah crew is all set so
changes are visible and data is looking
good so what we
like if I want to see the first movie
Avatar overview this like this dot dot
dot so I have to write here
like movies
overview
Overview at zeroth place
oh yeah
so this is a full overview of Avatar
movie like let me read for this in this
2017 Century uh paraplegic Marine is
dispatched and blah blah blah blah and
civilization
so moving forward that what we want to
recommend movie in the basis of overview
genre keyword cars so for that we need a
separate separate words like in the then
22nd century alone
so if you will see in other columns all
the words are separated but like here if
you will see all the words are separated
like action is subtracted Adventure is
updated fantasy it's separated
so
there is a long sentence in this this
one in the overview one these are long
sentence
so it's difficult to recommend from this
so what we are going to do is well we
will separate them like like other
columns so here we will write
movies
overview
let's do movies
and overview
and Dot apply
my bad sorry
then Lambda
colon x dot
split
error so let's see the results
so movies
yeah you can see in the section so now
you can see all the words are separated
by comma so now it will easy to match
overview to recommend a particular movie
so moving forward so what we are going
to do is if there is a two word and
space between there so we are going to
remove that space so here you can see
science fiction are separate separate
okay so we are going to re like remove
this one this is space
so let's write code for that
so here I will write like
overview is already done so we will do
not do for that so let's write code for
the rest columns
so here I have to write
movies
like
genres
pursue movies
and again
Jonas
dot apply
Lambda
X
I dot replace
mom
to no space
oh it seems good
then I have to write for
everywhere so for I in x
it's 4 I in x 4 I in x
movies genres equals to movie genres dot
apply Lambda X
I dot replace this to this for
Sims code
so let's copy paste this see
one for keywords and one for cast and
crew
asked
first
that you
that's the same so let me run this
okay no error seems good so let's see
the changes so movies
yeah
so now you can see the science fiction
space is gone like here is science
fiction space is there
now science fiction space is gone
so like okay
let's move forward and create one new
column name as tag and put all the
column data in a particular column
okay let me do first yeah let me write
movies
this is a column one column name equals
to movies
then first we will put overview
less movies
and Jonas
and movies
and what we have to give keywords
keywords
then again
movies
then
asked
let me run this
okay
so let's see the data frame movies
okay still coming so like there is one
problem I guess
yeah no no no
so here you can see all the data is
merged in a under attack column yes you
can see like in the second sensory blah
blah blah so
I hope you guys understand till here if
you have any question or any query
regarding any code
or anything just put as in comment or
our team will shortly provide you the
correct solution okay so I'm repeating
again I hope you guys understand till
here if you have any question or any
query regarding any code or like any
question just put as in command our team
will shortly provide you the correct
solution
so from here let's create a new data
frame
so let me create new data frame because
now we don't need this overview car
screw Joiner like columns like this we
have already merged into a one one
column like attack column so we will
write here new
DF equals to movies
so
like movies we need movie ID
new data frame we need movie ID comma we
need Title
and we have everything in tag column tax
column so we need tax column
okay let's run this let's see our new
data frame
so this is our new data look likes with
only three columns like a movie ID title
and tags so here you can see array
brackets like this this error brackets
so
we are gonna remove them so we will do
what we will write here we will write
new
data frame
that in tax
equals to
new
data frame
tags
dot apply
Lambda
X
then I will give space
dot join
themes good everything is okay okay fine
yeah
so let's see the results so
we will write a new underscore data
frame
so you can see the brackets are removed
now let's see the data which is present
in the zeroth index in tag column like
this dot dot in this
okay for that we have to write here
a new
data frame
tax
we did it before like for the overviewer
so you have to yeah
so this is the whole data in the first
like first index zeroth index so some
part of the overview like from
civilization and some are you can see
this action Advantage fantasy science
fiction these are some like genres
and
like here you can see like these are
some Crews members
and
yeah like Sam Worthington like there are
some cast crew okay
so like moving forward like what we are
going to do is just make them in lower
case for the better prediction like
something in capital something like
smaller so let's make it to
lowercase so new underscore DF
tax
equals to new underscore DF
tags
dot apply
column X
dot lower
okay
so don't worry about this error
let's see the result uh new underscore
DF
Dot
yeah now all the data present at TAG
column is in small case or you can say
lowercase moving forward let's do some
feature extraction using count
vectorizer so let's let me write first
from SK learn
Dot feature
instruction
feature extraction okay cool
dot text
import
count
vectorizer
DV equals to
count
riser
X underscore
features
features
equals to
5000.
oh
words
equals to
English
and this
yeah
so count vectorizer
okay there is a
that cannot import count vectorizer from
SQL and from user
okay okay sorry sorry my bad here V is
capital
okay guys so he be his Capital yeah so
no error so count vectorizer is a great
tool provided by the scikit-learn
library in Python it is used to
transform a given text into a vector on
the basis of the frequency count
of each word that occurs in the entire
text so
let me write something CV Dot
with underscore
transform
if
X
like dot to array
shape
okay
so the fit method like learns a
vocabulary dictionary of all tokens in
the Raw documents that is it creates a
dictionary of tokens by default the
tokens are words separated by spaces and
like punctuation so that Maps e single
token to a position in the output Matrix
so here CVS are like here CV is a
counter vectorizer so let's convert into
Vector to array so for this we have to
write vectors
vectors equals to CV dot fit
okay then transform
X
ing
so here we have to write
Dot
to array
yeah then we have to write
vector
its vectors
yeah you can see Vector 2 array all the
zeros
okay so moving forward let's get the
feature Name by writing
yeah so we will write here
Leanne LAN
chivi dot get
feature
names
okay then bracket
yeah
so okay we have like 500 feature names
so I'm repeating I'm saying again like I
hope you guys understand till here if
you have any question or any query
regarding any code whatever it is so
just put us in comments our team will
shortly provide you the correct solution
okay guys like any code or you are not
understand anything just put as in
comment our team will shortly provide
you the correct solution
so let's import some major Library which
is import
nltk
so what is nltk the natural language
toolkit nltk is a platform used for
building python programs that work with
human language
for applying in a statical network
language processing NLP it contains text
processing libraries for tokenization
parsing classification stemming tagging
and semantic reasoning
so moving forward like from let me write
first from
and
nltk
dot stem
dot Porter
import
ER
yes equals to
order
I mean is a process for reducing a word
to its word stem that suffix and prefix
or to the roots of words known as Alama
timing is important in natural language
understanding nlu and natural language
processing NLP
so here like I have to write
so here I will write F stem
text
y
equals to
or I in
text Dot split
y dot append
s dot stem
done
dot join
y
so let's apply this timing to attack
column so here we will write new DF
X
equals to
new
if
tag
dot apply
so let's import a cosine similarity from
SK learn so we will write from SK learn
dot matrices
Dot pairwise
import
cosine
underscore see me clarity
okay it seemed good from SQL and
matrices
metrics sorry Matrix Dot pairwise it is
[Music]
pairwise import cosine similarity okay
let's run this no error so cosine
similarity measures the similarity
between two Factor
the similarity between two vectors of an
inner product space it is measured by
the cosine of the angle between two
vectors and determines whether two
vectors are pointing in roughly the same
direction
it is often used to measure document
similarity in text analysis so here we
will write
cosine
underscore see me
clarity
vectors
so these all are the vector present
let's see the cosine similarity Vector
column and row using space
so here I will write cosine
because similarity
vectors
dot shape
so it's still running you can see here
yeah
so 4806 rows and four eight zero six
columns are there let's assign variable
similarity to this
OK so let's similarity
will write like this that equals to
cosine
similarity
is underscore here
I did this because we don't have to
write always this long sentence
a long keyword you can say
so moving forward let's see First Column
like we will add similarity
yeah so this is our first column uh so
let's see the rows only so we will write
here
t
0
Dot
shape
okay 4806 okay
so let's move forward and let's create
some like sorted list so
for that sorted
okay
paste
enumerate
spelling is fine
okay one more like similarity
similarity
0
where I have to write reverse
equals to true
comma key
equals to Lambda
colon
x dot capital x x
you have to write 1
colon six
seems good yeah
so the enumerate function in Python
converts a data collection object into
an enumerate object enumerate returns an
object that contains a counter as a key
for each value with an object making
item within a collection easier to
access so finally let's create the
recommend function to check the movie
recommendation system
okay
so
so let's write here d f
recommend
we
also new
DF
in the TF
title
costume movie
X
zero
tenses
versus similarity
and movie
okay so movies
list equals to sorted
rate
already
distances
reverse
pursue
true
keyword
sorry key only okay
equals to Lambda
colon X
1
.
6
or
I in movies
list
dot I lock
I
0
dot title we because we need Title only
so yeah it seems good okay
so finally that like time is game
so finally the time has come to check
the recommendation of your favorite
movies so you can comment in the chat
section so I can check
so let me write first recommend
recommend for movie
Avatar
okay
so here you can see the recommendation
system is working fine so Titan a DOT e
small soldier Independence Day are the
recommendation for the movie after so
let me check for the another one
recommend
like for
one of my favorite movie Iron Man
so here you can see Iron Man 2 Iron Man
3 Avengers Age of Ultron Captain America
and the Avengers are just
recommendations for the movie Iron Man
so let me check for the one more
recommend
layers
liar
things going on 30 and the last one is
last one I want to check is
Captain America Civil War
let me copy from here only
yeah you can see the Captain America the
First Avenger the Winter Soldier Iron
Man 3 age of ultron's The Avengers
so I hope you guys understand till here
if you have any questions or any query
regarding any code or question just put
us in comments our team will shortly
provide you the correct solution to an
aspiring AIML engineer then there is no
better time to train yourself in the
exciting field of AI if you are looking
for a course that covers everything from
fundamental to Advanced Techniques then
accelerate your career in Ai and ml with
our comprehensive postgraduate program
in Ai and machine learning so why wait
enroll now and unlock exciting AIML
opportunities the link is in the
description box below hello everyone
welcome to this session I'm Mohan from
Simply learn and today we'll talk about
interview questions for machine learning
now this video will probably help you
when you're attending interviews or
machine learning positions and attempt
here is to probably consolidate 30 most
commonly asked questions and to help you
in answering these questions we tried
our best to give you the best possible
answers but of course what is more
important here is rather than the
theoretical knowledge you need to kind
of add to the answers or supplementary
or answers with your own experience so
the responses that we put here are a bit
more generic in nature so that if there
are some Concepts that you are not clear
this video will help you in kind of
getting those Concepts cleared up as
well but what is more important is that
you need to supplement these responses
with your own practical experience okay
so with that let's get started so one of
the first questions that you may face is
what are the different types of machine
learning now what is the best way to
respond to this there are three types of
machine learning you read any material
you will always be told there are three
types of machine but what is important
is you would probably be better of
emphasizing that there are actually two
main types of emotional learning which
is supervised and unsupervised and then
there is a third type which is
reinforcement learn so supervised
learning is where you have some
historical data and then you feed that
data to your model to learn now you need
to be aware of a keyword that they will
be looking for which is labeled data
right so if you just say pass data or
historical data the impact may not be so
much you need to emphasize on labeled
data so what is labeled data basically
let's say if you are trying to do train
your model for classification you need
to be aware of for your existing data
which class each of the observations
belonged right so that is what is
labeling so it is nothing but a fancy
name you must be already aware but just
make it a point to throw in that keyword
labeled so that will have the right
impact
so that is what is supervised learning
when you have existing labeled data
which you then use to train your model
that is known as supervised learning and
unsupervised learning is when you don't
have this labeled data so you have data
it is not labeled so the system has to
figure out a way to do some analysis on
this okay so that is unsupervised
learning and you can then add a few
things like what are the ways of
performing a supervised learning and
unsupervised learning and what are some
of the techniques so supervised learning
we we perform or we do
regression and classification and
unsupervised learning video clustering
and clustering can be of different types
similarly regression can be of different
types but you don't have to probably
elaborate so much if they are asking for
just the different types you can just
mention these and just at a very high
level but if they want you to elaborate
give examples then of course I think
there is a different question
then the third so we have supervised and
we have unsupervised and then
reinforcement you need to provide a
little bit of information around as well
because it is sometimes a little
difficult to come up with a good
definition for reinforcement life so you
may have to little bit elaborate on how
reinforcement learning
right so reinforcement learning works in
in such a way that it basically has two
parts to it one is the agent and the
environment and the agent basically is
working inside of this environment and
it is given a Target that it has to
achieve and every time it is moving in
the direction of the target so the agent
basically has to take some action and
every time it takes an action which is
moving uh the agent towards the Target
right towards a goal a Target is nothing
but a goal then it is rewarded and every
time it is going in a direction where it
is away from the goal then it is
punished so that is the way you can
little bit explain and this is used
primarily or very very impactful or
teaching the system to learn games and
so on examples of this are basically
used in alphago you can throw that as an
example where alphaco used reinforcement
learning to actually learn to play the
game of Go and finally it defeated the
co-world champion all right this much of
information that would be good enough
then there could be a question on
overfitting uh so the question could be
what is overfitting and how can you
avoid it so what is overfitting so let's
first try to understand the concept
because sometimes overfitting Maybe
overfitting is a situation where the
model has kind of memorized the data so
this is an equivalent of memorizing the
data so we can draw an analogy so that
it becomes
becomes explainers now let's say you're
teaching a child about recognizing some
fruits or something like that
and you're teaching this child about
recognizing let's say three fruits
apples oranges and pineapples okay so
this is a small child and for the first
time you're teaching the child to
recognize fruits then so what will
happen so this is very much like that is
your training data set so what you will
do is you will take a basket of fruits
which consists of apples oranges and
pineapples
and you take this basket to this child
and there may be let's say hundreds of
these fruits so you take this basket to
this child and keep showing each of this
fruit and then first time obviously the
child will not know what it is so you
show an apple and you say hey this is
Apple then you show maybe an orange and
say this is orange and so on and so and
then again you keep repeating that right
so till that basket is over this is
basically how training work in machine
learning also that's how training works
so till the basket is completed maybe
100 fruits you keep showing this child
in the process what has happened the
child has pretty much memorized these so
even before you finish that basket right
by the time you are halfway through the
child has learned about recognizing the
Apple orange and pineapple now what will
happen after halfway through initially
you remember it made mistakes in
recognizing but halfway through now it
has learned so every time you show a
fruit it will exactly 100 accurately it
will identify it will say the child will
say this is an apple this is an orange
and if you show a pineapple it will say
this is a pineapple
Apple so that means it has kind of
memorized this data now let's say you
bring another basket of fruits and it
will have a mix of maybe apples which
were already there in the previous set
but it will also have in addition to
Apple it will probably have a banana or
maybe another fruit like a jackfruit
right so this is an equivalent of your
test data set which the child has not
seen before some parts of it it probably
has seen like the apples it has seen but
this banana and Jackfruit it has not
seen so then what will happen in the
first round which is an equivalent of
your training data set towards the end
it has 100 it was telling you what the
fruits are right Apple was accurately
recognized orange or I was accurately
recognized and pineapples were
accurately recognized right so that is
like a hundred percent accuracy but now
when you get another a fresh set which
were not a part of the original one what
will happen all the apples maybe it will
be able to recognize correctly but all
the others like the Jackfruit or the
banana will not be recognized by the
child right so this is an analogy this
is an equivalent of overfitting so what
has happened during the training process
it is able to recognize or reach 100
accuracy maybe very high accuracy okay
and we call that as very low loss right
so that is the technical term so the
loss is pretty much zero and accuracy is
pretty much hundred percent whereas when
you use testing there will be a huge
error which means the loss will be
pretty high and therefore the accuracy
will be also low okay this is known as
overfitting this is basically a process
where training is done training
processes it goes very well almost
reaching 100 accuracy but while testing
it really drops down now how can you
avoid it so that is the extension of
this question there are multiple ways of
avoiding overfitting there are
techniques like what you call
regularization that is the most common
technique that is used for avoiding
overfitting and within regularization
there can be a few other subtypes like
drop out in case of neural networks and
a few other examples but I think if you
give example or if you give
regularization as the technique probably
that should be sufficient so so there
will be some questions where the
interviewer will try to test your
fundamentals and your knowledge and
depth of knowledge and so on and so
forth and then there will be some
questions which are more like trick
questions that will be more to stop you
okay then the next question is around
the methodology so when we are
performing machine learning training we
split the data into training and test
right so this question is around that so
the question is what is training set and
test set machine learning model and how
is the split
the question can be
learning when we are trying to train the
model so we have a three-step process we
train the model and then we test the
model and then once we are satisfied
with the test only then we deploy the
model so what happens in the train and
test is that you remember the labeled
data so let's say you have 1000 records
with labeling information now one way of
doing it is you use all the Thousand
records for training and then maybe
right which means that you have exposed
all this thousand records during the
training process and then you take a
small set of the same data and then you
say okay I will test it with this okay
and then you probably what will happen
you may get some good results right but
there is a flaw there what is the flaw
this is very similar to human beings it
is like you are showing this model the
entire data as a part of training okay
so obviously it has become familiar with
the entire data so when you're taking a
part of that again and you're saying
that I want to test it obviously you
will get good results so that is not a
very accurate way of testing so that is
the reason what we do is we have the
label data of this thousand records or
whatever we set aside before starting
the training process we set aside a
portion of that data and we call that
test set and the remaining we call as
training set and we use only this for
training our model now the training
process remember is not just about
passing one round of this data set so
let's say now your training set has 800
records it is not just one time you pass
this 800 records what you normally do is
you actually as a part of the training
you may ask this data through the model
multiple times so this thousand records
may go through the model maybe 10 15 20
times still the training is perfect till
the accuracy is high till the errors are
minimized okay now so which is fine
which means that your that is what is
known as the model has seen your data
and gets familiar with your data and now
when you bring your test data what will
happen is this is like some new data
because that is where the real test is
now you have trained the model and now
you are testing the model with some data
which is kind of new that is like a
situation like like a realistic
situation because when the model is
deployed that is what will happen it
will receive some new data not the data
that it has already seen right so this
is a realistic test so you put some new
data so this data which you have set
aside is for the model it is new and if
it is able to accurately predict the
values that means your training has
worked okay the model got trained
properly but let's say while you are
testing this with this test data you're
getting lot of errors that means you
need to probably either change your
model or retrain with more data and
things like that
coming back to the question of how do
you split this what should be the ratio
there is no fixed number again this is
like individual preferences some people
split it into 50 50 test and 50 training
Some people prefer to have a larger
amount for training and a smaller amount
for test so they can go by either 60 40
or 70 30 or some people even go with
some odd numbers like 65 35 or
63.33 and 33 which is like one third and
two-thirds so there is no fixed rule
that it has to be something that's has
to be this you can go by your individual
preference all right then you may have
questions around data handling data
manipulation or what you call data
management or Preparation so these are
all some questions around that area
there is again no one answer one single
good answer to this it really varies
from situation to situation and
depending on what exactly is the problem
what kind of data it is how critical it
is what kind of data is missing and what
is the type of corruption so there are a
whole lot of things this is a very
generic question and therefore you need
to be little careful about responding to
this as well so probably have to
illustrate this again if you have
experience in doing this kind of work in
handling data you can illustrate with
examples saying that I was on one
project where I received this kind of
data these were the columns where data
was not filled or these were the this
many rows where the data was missing
that would be in fact a perfect way to
respond to this question but if you
don't have that obviously you have to
provide some good answer I think it
really depends on what exactly the
situation is and there are multiple ways
of handling the
data or corrupt data now let's take a
few examples now let's say you have data
where some values in some of the columns
are missing and you have pretty much
half of your data having these missing
values in terms of number of rows okay
that could be one situation another
situation could be that you have records
or data missing but when you do some
initial calculation how many records are
corrupt or how many rows or observations
as we call it has this missing data
let's assume it is very minimal like a
10 percent okay now between these two
cases how do we so let's assume that
this is not a mission critical situation
and in order to fix this 10 percent of
the data the effort that is required is
much higher and obviously effort means
also time and money right so it is not
so Mission critical and it is okay to
let's say get rid of these records so
obviously one of the easiest ways of
handling the data part or missing data
is remove those records or remove those
observations from your analysis so that
is the easiest way to do but then the
downside is as I said in as in the first
case if let's say 50 percent of your
data is like that because some column or
the other is missing so it is not like
every in every place in every Row the
same column is missing but you have in
maybe 10 percent of the records column
one is missing and another 10 percent
column two is missing another 10 percent
column three is missing and so on and so
forth so it adds up to maybe half of
your data set so you cannot completely
remove half of your data set then the
whole purpose is lost okay so then how
do you handle then you need to come up
with ways of filling up this data with
some meaningful value right that is one
way of handling so when we say
meaningful value what is that meaningful
right let's say for a particular column
you might want to take a mean value for
that column and fill wherever the data
is missing fill up with that mean value
so that when you're doing the
calculations your analysis is not
completely way off so you have values
which are not missing first of all so
your system will work number two these
values are not so completely out of
whack that your whole analysis goes for
a task right there may be situations
where if the missing values instead of
putting mean may be a good idea to fill
it up with the minimum value or with a
zero so or with a maximum value again as
I said there are so many possibilities
so there is no like one correct answer
for this you need to basically talk
around this and illustrate with your
experience as I said that would be the
best otherwise this is how you need to
handle this
okay so then the next question can be
how can you choose a classifier based on
a training set data size again this is
one of those questions where you
probably do not have like a one size
fits-all answer first of all you
may not let's say decide your classifier
based on the training set site maybe not
the best way to decide the type of the
classifier and even if you have to there
are probably some thumb rules which we
can use but then again every time so in
my opinion the best way to respond to
this question is you need to try out few
classifiers irrespective of the size of
the data and you need to then decide on
your particular situation which of these
classifiers are the right ones this is a
very generic issue so you will never be
able to just buy if somebody defines a
problem to you and somebody even if they
show the data to you or tell you what is
the data or even the size of the data I
don't think there is a way to really say
that yes this is the classifier that
will work here no that's not the right
way so you need to still you know test
it out get the data try out a couple of
classifiers and then only you will be in
a position to decide which classifier to
use you try out multiple classifiers see
which one gives the best accuracy and
only then you can decide then you can
have a question around confusion Matrix
so the question can be explained
confusion Matrix right so confusion
Matrix I think the best way to explain
it is by taking an example and drawing
like a small diagram otherwise it can
really become tricky so my suggestion is
to take a piece of pen and paper and
explain it by drawing a small Matrix and
confusion Matrix is about to find out
this is used especially in
classification learning process and when
you get the results when the our model
predicts the results you compare it with
the actual value and try to find out
what is the accuracy okay so in this
case let's say this is an example of a
confusion Matrix and it is a binary
Matrix so you have the actual values
which is the labeled data right and
which is so you have how many yes and
how many know so you have that
information and you have the predicted
values how many yes and how many now
right so the total actual value is the
total yes is 12 plus 130 and they are
shown here and the actual value those
are 9 plus 3 12 okay so that is what
this information here is so this is
about the actual and this is about the
predicted similarly the predicted values
there are yes are 12 plus 3 15 yeses and
no are 1 plus 9 10 nodes okay so this is
the way to look at this confusion Matrix
okay and uh out of this what is the
meaning converting so there are two or
three things that needs to be explained
out right the first thing is for a model
to be accurate the values across the
diagonal should be high like in this
case right that is one number two the
total sum of these values is equal to
the total observations in the test data
set so in this case for example you have
12 plus 3 15 plus 10 25 so that means we
have 25 observations in our test data
set okay so these are the two things you
need to First explain that the total sum
in this Matrix the numbers is equal to
the size of the test data set and the
diagonal values indicate the accuracy so
by just by looking at it you can
probably have a idea about is this an
accurate model is the model being
accurate if they're all spread out
equally in all these four boxes that
means probably the accuracy is not very
good okay now how do you calculate the
accuracy itself right how do you
calculate the accuracy itself so it is a
very simple mathematical calculation you
take some of the diagonals right so in
this case it is 9 plus 12 21 and divide
it by the total so in this case what
will it be let me uh take a pen so your
your diagonal values is equal to if I
say t is equal to 12 plus 9 so that is
21 right and the total data set is equal
to right we just calculated it is 25 so
what is your accuracy it is 21 by your
accuracy is equal to 21 by 25 and this
turns out to be about 85 percent right
so this is 85 percent so that is our
accuracy okay so this is the way you
need to explain draw diagram Give an
example and maybe it may be a good idea
to be paired with an example so that it
becomes easy for you don't have to
calculate those numbers on the fly right
so a couple of hints are that you take
some numbers which are with which add up
to 100 that is always a good idea so you
don't have to really do this complex
calculations so the total value will be
100 and then diagonal values you divide
once you find the diagonal values that
is equal to your percentage okay all
right so the next question can be a
related question about false positive
and false negative so what is false
positive and what is false negative now
once again the best way to explain this
is using a piece of paper and then
otherwise it will be pretty difficult to
so we use the same example of the
confusion Matrix
and we can explain that so A confusion
Matrix looks somewhat like this and when
we just
somewhere like this and we continue with
the previous example where this is the
actual value this is the predicted value
and in the actual value we have 12 plus
1 13 yeses and 3 plus 9 12 nose and the
predicted values there are 12 plus the
15 yeses and 1 plus 9 10 loss okay now
this particular case which is the false
positive what is a false positive first
of all the second word which is positive
okay is referring to the predicted value
so that means the system has predicted
it as a positive but the real value so
this is what the false comes from but
the real value is not positive okay that
is the way you should understand this
term false positive or even false
negative so false positive so positive
is what your system has predicted so
where is that system predicted this is
the one positive is what yes so you
basically consider this row okay now if
you consider this row so this is this is
all positive values this entire row is
positive values okay now the false
positive is the one which where the
value actual value is negative predicted
value is positive but the actual value
is negative so this is a false positive
right and here is a true positive so the
predicted value is positive and the
actual value is also positive okay I
hope this is making sense now let's take
a look at what is false negative false
negative so negative is the second term
that means that is the predicted value
that we need to look for so which are
the predicted negative values this row
corresponds to predicted negative values
all right so this row corresponds to
predicted negative values and what they
are asking for false so this is the row
for predicted negative values and the
actual value is this one right this is
predicted negative and the actual value
is also negative therefore this is a
true negative so the false negative is
this one predicted is negative but
actual is positive right so this is the
false negative so this is the way to
explain and this is the way to look at
false positive and false negative same
way there can be true positive and true
negative as well so again positive the
second term you will need to use to
identify the a predicted row right so if
we say true positive positive we need to
take for the predicted part so predicted
positive is here okay and then the first
term is for the actual so true positive
so true in case of actual is yes right
so true positive is this one okay and
then in case of actual the negative now
we are talking about let's say true
negative true negative negative is this
one and the true comes from here so this
is true negative right 9 is true
negative the actual value is also
negative and the predicted value is also
negative okay so that is the way you
need to explain this the terms false
positive false negative and true
positive true negative then uh you might
have a question like what are the steps
involved in the machine learning process
or what are the three steps in the
process of developing a machine learning
model right so it is around the
methodology that is applied so basically
the way you can probably answer in your
own words but the way the model
development of the machine learning
model
so first of all you try to understand
the problem and try to figure out
whether it is a classification problem
or a regression problem based on that
you select a few algorithms and then you
start the process of training these
models
so you can either do that or you can
after due diligence you can probably
decide that there is one particular
algorithm which is more suitable usually
it happens through trial and error
process but at some point you will
decide that okay this is the model we
are going to use okay so in that case we
have the model algorithm and the model
decided and then you need to do the
process of training the model and
testing the model and this is where if
it is supervised learning you split your
data the label data into training data
set and test data set and you use the
training data set to train your model
and then you use the test data set to
check the accuracy whether it is working
fine or not so you test the model before
you actually put it into production
right so once you test the model you're
satisfied it's working fine then you go
to the next level which is putting it
for production and then in production
obviously new data will come and
inference happens so the model is
readily available and only thing that
happens is new data comes and the model
predicts the values
you know so this can be an iterative
process so it is not a straightforward
process where you do the training
through the testing and then you move it
to production now so during the training
and test process there may be a
situation where because of either
overfitting or things like that the test
doesn't go through which means that you
need to put that back into the training
process so that can be a an iterative
process not only that even if the
training and test goes through properly
and you deploy the model in production
there can be a situation that the data
that actually comes the real data that
comes with that this model is failing so
in which case you may have to once again
go back to the drawing board or
initially it will be working fine but
over a period of time maybe due to the
change in the nature of the data once
again the accuracy will iterate so that
is again a recursive process so once in
a while you need to keep checking
whether the model is working fine or not
and if required you need to tweak it and
modify it and so on and so forth so let
net this is a continue us process of
tweaking the model and testing it and
making sure it is up to date then you
might have question around deep learning
so because deep learning is now
associated with AI artificial
intelligence and so on so it can be as
simple as what is deep learning so I
think the best way to respond to this
could be deep learning is a part of
machine learning and then obviously the
question would be then what is the
difference right so deep learning you
need to mention there are two key parts
that interviewer will be looking for
when you are defining deep learning so
first is of course deep learning is a
subset of machine learning so machine
learning is still the bigger let's say
scope and deep learning is one one part
of it so then what exactly is the
difference deep learning is primarily
when we are implementing these our
algorithms or when we are using neural
networks for doing our training and
classification and regression in our
right so when we use neural network then
it is considered as deep learning and
the term deep comes from the fact that
you can have several layers of neural
networks and these are called Deep
neural networks and therefore the term
deep you know deep learning uh the other
difference between machine learning and
deep learning which the interviewer may
be wanting to hear is that in case of
machine learning the feature engineering
is done manually what do we mean by
feature engineering basically when we
are trying to train our model we have
our training data right so we have our
training label data and this data has
several let's say if it is a regular
table it has several columns now each of
these columns actually has information
about a feature right so if we are
trying to predict the height weight and
so on and so forth so these are all
features of human beings let's say we
have census data and we have all this so
those are the features now that may be
probably 50 or 100 in some cases there
may be 100 such features now all of them
do not contribute to our model right so
we as a data scientist we have to decide
whether we should take all of them all
the features or we should throw away
some of them because again if we take
all of them number one of course your
accuracy will probably get affected but
also there is a computational part so if
you have so many teachers and then you
have so much data it becomes very tricky
so in case of machine learning we
manually take care of identifying the
features that do not contribute to the
learning process and thereby we
eliminate those features and so on right
so this is known as feature engineering
and in machine learning we do that
manual whereas in deep learning where we
use neural networks the model will
automatically determine which features
to use and which to not use and
therefore feature engineering is also
done automatically so this is a
explanation these are two key things
from probably will add value to your
response alright so the next question is
what is the difference between or what
are the differences between machine
learning and deep learning so here this
is a quick comparison table between
machine learning and deep learning and
in machine learning learning enables
missions to take decisions on their own
based on past data so here we are
talking primarily of supervised learning
and it needs only a small amount of data
for training and then works well on low
end system so you don't need a large
and most features need to be identified
in advance and manually coded so
basically the feature engineering part
is done manually and the problem is
divided into parts and solved
individually and then combined so that
is about the machine learning part in
deep learning deep learning basically
enables machines to take decisions with
the help of artificial neural network so
here in deep learning we use neural line
so that is the key differentiator
between machine learning and deep
learning and usually deep learning
involves a large amount of data and
therefore the training also requires
usually the training process requires
high-end machines as needs a lot of
computing power and the Machine learning
features are the or the feature
engineering is done automatically so the
neural networks takes care of doing the
feature engineering as well and in case
of deep learning therefore it is said
that the problem is handled end to end
so this is a quick comparison between
machine learning and deep learning in
case you have that kind of a question
then you might get a question around the
uses of machine learning or some real
life applications of machine learning in
modern business the question may be
worded in different ways but the meaning
is how exactly is machine learning used
or actually supervised machine learning
it could be a very specific question
around supervised decision learning so
this is like give examples of supervised
machine learning use of supervised
machine learning in modern business so
that could be the next question so there
are quite a few examples or quite a few
use cases if you will for supervised
machine learning the very common one is
email spam detection so you want to
train your application or your system to
detect between spam and non-spam so this
is a very common business application of
a supervised machine learning so how
does this work the way it works is that
you obviously have historical data above
of your emails and they are categorized
as spam and not spam so that is what is
the labeled information and then you
feed this information or the all these
emails as an input to your model right
and the model will then get trained to
detect which of the emails are to detect
which is Spam and which is not spam so
that is the training process and this is
supervised machine learning because you
have labeled data you already have
emails which are tagged as spam or not
and then you use that to train your
model right so this is one example now
there are a few industry specific
applications for supervised machine
learning one of the very common ones is
a healthcare Diagnostics in healthcare
Diagnostics you have these images and
you want to train models to detect
whether from a particular image whether
it can find out if the person is sick or
not whether a person has cancer or not
right so this is a very good example of
supervised machine learning here the way
it works is that existing images it
could be x-ray images it will be MRI or
any of these images are available and
they are saying that okay this x-ray
image is deflective of the person has an
illness or it could be cancer whichever
illness right so it is stacked as
defective or clear or good image and
effectively something like that so we
come up with a binary or it could be
multi-class as well saying that this is
defective to 10 percent this is 25 and
so on but let's keep it simple you can
give an example of just a binary
classification that would be good enough
so you can say that in healthcare
Diagnostics using image we need to
detect whether a person is ill or
whether a person is having
here the way it works is you feed
labeled images and you allow the model
to learn from that so that when New
Image is fed it will be able to predict
whether this person is having that
illness or not having cancer or not
right so I think this would be a very
good example for supervised machine
learning in modern business all right
then we can have a question like so
we've been talking about supervised and
unsupervised then so there can be a
question around semi-supervised machine
learning so what is semi-supervised
machine learning now semi-supervised
learning as the names such as it falls
between supervised learning and
unsupervised learning but for all
practical purposes it is considered as a
art of supervised learning and the
reason this has come into existence is
that in supervised learning you need
labeled data so all your data for
training your model has to be labored
now this is a big problem in many
Industries or in many under many
situations getting the label data is not
that easy because there's a lot of
effort in labeling this data let's take
an example of diagnostic images we just
let
three images now there are actually
millions of x-ray images available all
over the world but the problem is they
are not labeled so their images are
there but whether it is effective or
whether it is good and information is
not available along with it right in a
form that it can be used by a machine
which means that somebody has to take a
look at these images and usually it
should be like a doctor and then say
that okay yes this image is clean and
this image is cancerous and so on and so
forth now that is a huge effort by
itself so this is where semi-supervised
learning comes into play so what happens
is there is a large amount of data maybe
a part of it is labeled then we try some
techniques to label the remaining part
of the data so that we get completely
labeled data and then we train our model
so I know this is a little long winding
explanation but unfortunately there is
no quick and easy definition for
semi-supervised machine learning this is
the only way probably to explain this
concept
we may have another question as what are
unsupervised machine learning techniques
or what are some of the techniques used
for performing unsupervised machine
learning so it can be worded in a
different ways so how do we answer this
question so unsupervised learning you
can say that there are two types
clustering and Association and
clustering is a technique where similar
objects are put together and there are
different ways of finding similar
objects so their characteristics can be
measured and if they have in most of the
characteristics if they are similar then
they can be put together
then Association you can I think the
best way to explain Association is with
an example in case of Association you
try to find out how the items are linked
to each
example if somebody bought maybe a
laptop or the person has also purchased
a mouse so this is more in an e-commerce
scenario for example so you can give
this as an example so people who are
buying and laptops are also buying the
mouse so that means there is an
association between laptops and
tops and people who are buying red are
also buying buying butter so that is the
association that can be created so this
is unsupervised learning one of the
techniques
all right then we have very fundamental
question what is the difference between
supervised and unsupervised machine
learning so machine learning these are
the two main types of machine learning
supervised and unservised and in case of
supervised and again here probably the
key word that the person may be wanting
to hear is labeled data now very often
people say we have historical data and
if we run it it is supervised and if we
don't have historical data yes but you
may have historical data but if it is
not labeled then you cannot use it for
so it is it's very key to understand
that we put in that keyword label okay
so when we have labeled data for
training our model then we can use
supervised learning and if we do not
have labeled data then we use
unsupervised learning and there are
different algorithms available to
perform both of these
so there can be another question a
little bit more theoretical and
conceptual in nature this is about
inductive machine learning and
machine learning so the question can be
what is the difference between inductive
machine learning and deductive machine
learning or somewhat in that manner so
that's the exact phrase or exact
question
really they can ask for examples and
things like that but that could be the
question so let's first understand what
is inductive and deductive training
inductive training is induced by
somebody and you can illustrate that
with a small example I think that always
helps so whenever you're doing some
exclamation try as much as possible as I
said to give examples from your work
experience or give some analogies and
that will also help a lot in explaining
as well and for the interviewer also to
understand so here we'll take an example
or rather we will use an analogy so
inductive training is when we induce
some knowledge or the learning process
into a person without the person
actually experiencing it what can be an
example so we can probably tell the
person or show a person a video that
fire can burn the thing burn his finger
or fire can cause damage so what is
happening here this person has never
probably seen a fire or never seen
anything getting damaged by fire but
just because he has seen this video he
knows that okay fire is dangerous and if
a fire can cause damage right so this is
inductive learning compared to that what
is deductive learning so here you draw
conclusion or the person draws
conclusion out of experience so we will
stick to the analogy so compared to the
showing a video Let's assume a person is
allowed to play with fire right and then
he figures out that if he puts his
finger it's burning or you throw
something into the fire it burns so he
is learning through experience so this
is known as deductive learning okay so
you can have applications or models that
can be trained using inductive learning
or deductible
all right I think probably that
explanation will
sufficient the next question is are knnn
and K means clustering similar to one
another or are they same right because
the the letter K is kind of common
between them okay so let us take a
little while to understand what these
two are one is KNN another is K means k
n stands for K nearest neighbors and K
means of course is the clustering
mechanism now these two are completely
different except for the letter K being
common between them KN is completely
different K means clustering is complete
KNN is a classification process and
therefore it comes under supervised
learning whereas k-means clustering is
actually a unsupervised okay when you
have K and N when you want to implement
k n n which is basically K nearest
neighbors the value of K is a number so
you can say k is equal to 3 you want to
implement KN with K is equal to 3 so
which means that it performs the
classification in such a way that how
does it perform the classification so it
will take three nearest objects and
that's why it's called nearest neighbor
so basically uh based on the distance it
will try to find out its nearest objects
that are let's say three of the nearest
objects and then it will check whether
the class they belong to which class
right so if all three belong to one
particular class obviously this new
object is also classified as that
particular
but it is possible that they may be from
two or three different classes okay so
let's say they are from two classes and
then if they are from two classes now
usually you take a odd number you assign
odd number two so if there are three of
them and two of them belong to one class
and then one belongs to another class so
this new object is assigned to the class
to which the two of them belong now the
value of K is sometimes tricky whether
should you use three should you use five
should you use seven that can be tricky
because the ultimate classification can
also vary so it's possible that if
you're taking K as3 the object is
probably in one particular class but if
you take K is equal to 5 maybe the
object will belong to a different class
because when you're taking three of them
probably two of them belong to a class
one and one belong to class two whereas
when you take five of them it is
possible that only two of them belong to
class one and the three of them belong
to Class 2 so which means that this
object will belong to class 2 right so
you see that so it is the class
allocation can vary depending on the
value of K now K means on the other hand
is a clustering process and it is
unsupervised where what it does is the
system will basically identify how the
objects are how close the objects are
with respect to some of their features
okay and but the similarity of course is
the the letter K and in case of K means
also we specify its value and it could
be three or five or seven there is no
technical limit as such but it can be
any number of clusters that you can
create okay so based on the value that
you provide the system will create that
many clusters of similar objects there
is a similarity to that extent that K is
a number in both the cases but actually
these two are completely different
processes
we have what is known as naive base
classifier and people often get confused
thinking that naive base is the name of
the person who found this classifier or
who developed this classifier which is
not 100 True base is the name of the
person bais is the name of the person
but naive is not the name of the person
right so naive is basically an English
word and that has been added here
because of the nature of his particular
classifier an ibase classifier is a
probability based classifier and it
makes some assumptions that presence of
one feature of a class is not related to
the presence of any other feature of
maybe other classes right so which is
not a very strong or not a very what do
you say accurate assumption because
these features can be related and so on
but even if we go with this assumption
this whole algorithm works very well
even with this assumption and uh that is
the good side of it but the term comes
from that so it is the explanation that
you can
then there can be question around
reinforcement learning it can be
paraphrased in multiple ways one could
be can you explain how a system can play
a game of chess using
using or it can be any
unique the best way to explain this is
again to talk a little bit about what
reinforcement learning is about and then
elaborate on that to explain the process
so first of all reinforcement learning
has an environment and an agent and
agent is basically performing some
actions in order to achieve a certain
goal and this goals can be anything
either it is related to game then the
goal could be that you have to score
very high score
or it could be that your number of lives
should be as high as possible don't lose
life so this could be some of them a
more advanced examples could be for
driving the automotive industry
self-driving cars they actually also
make use of reinforcement learning to
teach the car how to navigate through
the roads and so on and so forth that is
also another example now how does it
work so if the system is basically there
is an agent and environment and every
time the agent takes a step or performs
a task which is taking it towards the
goal the final goal let's say to
maximize the score or to minimize the
number of lives and so on or minimize
that
well it is rewarded and every time it
takes a step which goes against that
core right contrary or in the reverse
Direction it is penalized okay so it is
like a character elastic
now how do you use this to create a game
of chess so to create a system to play a
game on chess now the way this works is
and this could probably go back to this
alphago example where alphaco defeated a
human Champion so the way it works is in
reinforcement learning this system is
allowed for example if in this case we
are talking about Chess so we allow the
system to first of all watch playing a
game of chess it could be with a human
being or it could be the system itself
there are computer games of Chess right
so either this new learning system has
to watch that game or watch a human
being play the game and because this is
reinforcement learning is pretty much
all visual so when you're teaching the
system to play a game the system will
not actually go behind the scenes to
understand the logic of your software of
this game or anything like that it is
just visually watching the screen and
then it learns okay so reinforcement
learning to a large extent it works on
that so you need to create a mechanism
whereby your model will be able to watch
somebody playing the game and then you
allow the system also to start playing
the game so it pretty much starts from
scratch okay and as it moves forward it
it's at right at the beginning the
system really knows nothing about the
game of chess okay so initially it is a
clean slate it just starts by observing
how you are playing so it will make some
random moves and keep losing badly but
then what happens is over a period of
time so you need to now allow the system
or you need to play with this system not
just one two three four or five times
but hundreds of times thousands of times
maybe even hundreds of thousands of
times and that's exactly how alphago has
done it played millions of games between
itself and the system right so for the
game of chess also you need to do
something like that you need to allow
the system to play chess and and learn
on its own over a period of repetition
so I think you can probably explain it
to this much to this extent and I
now this is another question which is
again somewhat similar but here the size
is not coming Richa so the question is
how will you know which machine learning
algorithm to choose for your
classification problem now this is not
only classification problem it could be
a regression problem I would like to
generalize this question so if somebody
asks you how will you choose how will
you know which algorithm to use the
simple answer is there is no way you can
decide exactly saying that this is the
algorithm I am going to use in a variety
of situations there are some guidelines
like for example you will obviously
depending on the problem you can say
whether it is a classification problem
or a regression problem and then in that
sense you are kind of restricting
yourself to if it is a classification
problem there are you can only apply a
classification algorithm right to that
extent you can probably let's say limit
the number of algorithms but now within
the classification algorithms you have
decision trees you have SPM you have
logistic regression is it possible to
outright say yes so for this particular
problem since you have explained this
now this is the exact algorithm that you
can use that is
okay so we have to try out a bunch of
algorithms see which one gives us the
best performance best accuracy and then
decide to go with that particular
algorithm so in machine learning a lot
of it happens through trial and error
there is no real possibility that
anybody can just by looking at the
problem or understanding the problem
tell you that okay in this particular
situation this is exactly the algorithm
that you should use then the questions
may be around application of machine
learning and this question is
specifically around how Amazon is able
to recommend other things to buy so this
is around recommendation engine how does
it work how does the recommendation
engine work this is basically the
question is all about so the
recommendation engine again Works based
on various inputs that are provided
obviously something like uh you know
Amazon on a website or e-commerce site
like Amazon collects a lot of data
around the customer Behavior who is
purchasing what and if somebody is
buying a particular thing they are also
buying something else so this kind of
Association right so this is the
unsupervised learning we talked about
they use this to associate and Link or
relate items and that is one part of it
so they kind of build association
between items saying that somebody
buying this is also buying this that is
one part of it then they also profile
the users right based on their age their
gender their geographic location they
will do some profiling and then when
somebody is logging in and when somebody
is shopping kind of the mapping of these
two things are done they try to identify
obviously if you have logged in then
they know who you are and your
information is available like for
example your age maybe your agenda and
where you're located what you purchased
earlier right so all this is taken and
the recommendation engine basically uses
all this information and comes up with
recommendations for a particular user so
that is how the recommendation engine
work all right then the question can be
something very basic like when will you
go for classification versus regression
right when do you do classification
instead of instead of regression or when
will you use classification instead of
regression now yes so so this is
basically going back to the
understanding of the basics of
classification and regression so
classification is used when you have to
identify or categorize things into
discrete classes so the best way to
respond to this question is to take up
some examples and use it otherwise it
can become a little tricky the question
may sound very simple but explaining it
can sometimes be very tricky in case of
regression the use of course there will
be some keywords that they will be
looking for so just you need to make
sure you use those keywords one is the
discrete values another is the
continuous values so for regression if
we are trying to find some continuous
values you use regression whereas if you
are trying to find some discrete values
you use classification and then you need
to illustrate what are some of the
examples so classification is like let's
say there are images and you need to put
them into classes like cat dog elephant
tiger something like that so that is the
classification problem or it can be that
is a multi-class classification problem
it could be binary classification
problem like for example whether a
customer will buy or he will not buy
that is a classification binary
classification it can be in the weather
forecast area now weather forecast is
again combination of regression and
classification because on the one hand
you want to predict whether it's going
to rain or not it's a classification
problem that's a binary classification
right whether it's going to rain or not
rain however you also have to predict
what is going to be the temperature
tomorrow right now temperature is a
continuous value you can't answer the
temperature in a yes or no kind of a
response right so what will be the
temperature tomorrow so you need to give
a number which can be like 20 degrees 30
degrees or whatever right so that is
where you use regression one more
example is stock price prediction so
that is where again you will use
regression so these are the various
examples so you need to illustrate with
examples and make sure you include those
keywords like discrete and continue so
the next question is more about a little
bit of a design related question to
understand your Concepts and things like
that so it is how will you design a spam
filter so how do you basically design or
developer
developers so I think the main thing
here is he's looking at probably
understanding your Concepts in terms of
uh what is the algorithm you will use or
what is your understanding about
difference between classification and
regression
regression things like that right and
the process of course the neurology and
the process so the best way to go about
responding to this is we say that okay
this is a classification problem
we want to find out whether an email is
a spam or not spam so that we can apply
the filter accordingly so first thing is
to identify what type of a problem it is
so we have identified that it is a
classification then the second step may
be to find out what kind of algorithm to
use now since this is a binary
classification problem logistic
regression is a very common very common
algorithm but however right as I said
earlier also we can never say that okay
for this particular problem this is
exactly the algorithm that we can use so
we can also probably try decision trees
or even support Vector machines for
example svm so we will kind of list down
a few of these algorithms and we will
say okay we want to we would like to try
out these algorithms and then we go
about taking your historical data which
is the labeled data which are marked so
you will have a bunch of emails and then
you split that into training and test
data sets you use your training data set
to train your model that or your
algorithm that you have used or rather
the model actually so and you actually
will have three models let's say you are
trying to test out three algorithms so
you will obviously have three models so
you need to try all three models and
test them out as well see which one
gives the best accuracy and then you
decide that you will go with that model
okay so training and test will be done
and then you zero in on one particular
model and then you say okay this is the
model will you use we will use and then
go ahead and Implement that or put that
in production so that is the way you
design a spam the next question is about
random Forest what is random form so
this is a very straightforward question
however the response you need to be
again a little careful while we all know
what is random Forest explaining this
can sometimes be tricky so one thing is
random Forest is kind of in one way it
is an extension of decision trees
because it is basically nothing but you
have multiple decision trees and trees
will basically we will use for doing if
it is classification mostly it is
classification you will use the the
trees for classification and then you
use voting for finding the final class
so that is the underlyings but how will
you explain this how will you respond to
this so first thing obviously we will
say that random Forest is one of the
algorithms and the more important thing
that you need to probably the
interviewer is is waiting to here is
Ensemble learner right so this is one
type of Ensemble learner what is
Ensemble learner Ensemble learner is
like a combination of algorithms so it
is a learner which consists of more than
one algorithm or more than one or maybe
models okay so in case of random Forest
the algorithm is the same but instead of
using one instance of it we use multiple
instances of it and we use so in a way
that is a random Forest is an ensemble
now there are other types of Ensemble
Learners where we have like reuse
different algorithms itself so you have
one maybe logistic regression and a
decision tree combined together and so
on and so forth or there are other ways
like for example splitting the data in a
certain way and so on so that's all
about on some
that but random Forest itself I think
the interviewer will be happy to hear
this word Ensemble Learners and so then
you go and explain how the random Forest
works so if the random Forest is used
for classification then we use what is
known as a voting mechanism so basically
how does it work let's say your item
Forest consists of 100 trees and each
observation you pass through this forest
and each observation let's say it is a
classification problem binary
classification zero or one and you have
100 trees now if 90 trees say that it is
a zero and ten of the trees say it is a
one you take the majority you may take a
vote and since 90 of them are saying
zero you classify this as zero then you
take the next observation and so on so
that is the way random Forest works for
classification if it is a regression
problem it's somewhat similar but only
thing is instead of what what we will do
is sorry in regression remember what
happens you actually calculate a value
right so for example you're using
regression to predict the temperature
and you have 100 trees and each tree
obviously will probably predict a
different value of the temperature they
may be close to each other but they may
not be exactly the same value so these
hundred trees so how do you now find the
actual value the output for the entire
Forest right so you have outputs of
individual trees which are a part of
this Forest but then you need to find
the final output of the forest itself so
how do you do that so in case of
regression you take like an average or
the mean of all the 100 trees right so
this is also a way of reducing the error
so maybe if you have only one tree and
that one tree makes a header it is
basically hundred percent wrong 100
right right but if you have on the other
hand if you have a bunch of trees you
are basically indicating that and
reducing that error okay so that is the
way random Forest works so the next
question is considering the long list of
machine learning algorithms how will you
decide on which one to use so once again
here there is no way to outright say
that this is the algorithm that we will
use for a given data set this is a very
good question but then the response has
to be like again there will not be a
one-size-fits all so we need to first of
all you can probably shorten the list in
terms of by saying okay whether it is a
classification problem or it is a
regression problem to that extent you
can probably shorten the list because
you don't have to use all of them if it
is a classification problem you only can
pick from the classification algorithm
right so for example if it's a class
station you cannot use linear regression
algorithm or if it is a regression
problem you cannot use svm or maybe now
you can use svm but maybe a logistic
regression right so to that extent you
can probably shorten the list but still
you will not be able to 100 decide on
saying that this is the exact algorithm
that I am going to use so the way to go
about is you choose a few algorithms
based on what the problem is you try out
your data you train some models of these
algorithms check which one gives you the
lowest error or the highest accuracy and
based on that you choose that particular
algorithm all right then they can be
questions around bias and variants so
the question can be what is bias and
variance in machine learning uh so you
just need to give out a definition for
each of these for example a bias in
machine learning it occurs when the
predicted values are far away from the
actual value so that is the bias okay
and whereas they are all all the values
are probably they are far off but they
are very near to each other though the
predicted values are close to each other
right while they are far off from the
actual value but they are close to each
other you see the difference so that is
bias and then the other part is your
variance now variance is when the
predicted values are all over the place
right so the variance is high that means
it may be close to the Target but it is
kind of very scattered so the point the
predicted values are not close to each
other right in case of bias the
predicted values are close to each other
but they are not close to the Target but
here they may be close to the Target but
they may not be close to each other so
they are a little bit more scattered so
that is what in case of a variance okay
then the next question is about again
related to bias and variance what is the
trade-off between bias and variance yes
I think this is a interesting question
because these two are heading in
different directions so for example if
you try to minimize the bias variance
will keep going high and if you try to
minimize the variance bias will keep
going high and there is no way you can
minimize both of them so you need to
have a trade-off saying that okay this
is the level at which I I will have my
bias and this is the level at which I
will have variance so the trade-off is
that pretty much attack you you decide
what is the level you will tolerate for
your bias and what is the level you will
tolerate for variance and a combination
of these two in such a way that your
final results are not way off and having
a trade-off will ensure that the results
are consistent right so that is
basically the output is consistent and
which means that they are close to each
other and they are also accurate which
that means they are as close to the
Target as possible right so if either of
these is high then one of them will go
off the track define precision and
Recall now again here I think it would
be best to draw a diagram and take up in
the confusion Matrix and it is very
simple the definition is like a formula
your Precision is true positive by true
positive plus false positive and your
recall is true positive by true positive
plus false negative okay so that's you
can just show it in a mathematical way
that's pretty much uh
that's the easiest way to define so the
next question can be about decision tree
what is decision tree pruning and why is
it so basically decision trees are
really simple to implement and
understand but one of the drawbacks of
decision trees is that it can become
highly complicated as it grows right and
the rules and conditions can become very
complex
and this can also lead to overfitting
which is basically that during training
you will get 100 accuracy but when
you're doing testing you'll get a lot of
Errors so that is the reason pruning
needs to be done so the purpose or the
reason for doing decision tree pruning
is to reduce overfitting or to cut down
on our fitting and what is decision tree
pruning it is basically that you reduce
the number of branches because as you
may be aware a tree consists of the root
node and then there are several internal
nodes and then you have the leaf nodes
now if there are too many of these
internal nodes that is when you face the
problem of overfitting and pruning is
the process of reducing those internal
nodes all right so the next question can
be what is logistic regression uh so
basically logistic regression is one of
the techniques used for performing
classification especially binary
classification now there is something
special about logistic regression and
there are a couple of things you need to
be careful about first of all the name
is a little confusing it is called
logistic regression but it is used for
classification so this can be sometimes
confusing so you need to probably
clarify that to the interviewer if it's
really in
required and they can also ask this like
a request
the question thing is the term logistic
has nothing to do with the usual
Logistics that we talk about but it is
derived from the log so that the
mathematical derivation was log and
therefore the name
so what is logistic regression and how
is it used so logistic regression is
used for binary classification and the
output of a logistic regression is
either a zero or a one and it varies so
it's basically it calculates a
probability between 0 and 1 and we can
set a threshold that can vary typically
it is 0.5 so any value above 0.5 is
considered as 1 and if the probability
is below 0.5 it is considered as 0. so
that is the way we calculate the
probability of the system calculates the
probability and based on the threshold
it sets a value of 0 or 1 which is like
a binary classification zero or one okay
then we have a question around K nearest
neighbor algorithm so explain K nearest
neighbor algorithm so first of all what
is the K nearest neighbor algorithm this
is a classification algorithm so that is
the first thing we need to mention and
we also need to mention that the K is a
number it is an integer and this is
variable and we can Define what the
value of K should be it can be 2 3 5 7
and usually it is an odd number so that
is something we need to mention
technically it can be even number also
but then typically it would be odd
number and we will see why that is okay
so based on that we need to classify
objects okay we need to classify objects
so again it will be very helpful to draw
a diagram you know if you are explaining
I think that will be the best way so
draw some diagram like this and let's
say we have three clusters or three
classes existing and now you want to
find for a new item that has come you
want to find out which class this
belongs right so you go about as the
name suggests it you go about finding
the nearest neighbors right the points
which are closest to this and how many
of them you will find point that is what
is defined by K now let's say our
initial value of K was Phi so you will
find the K the five nearest data points
so in this case as it is Illustrated
these are the five nearest data points
but then all five do not belong to the
same class or cluster so there are one
belonging to this cluster one the second
one belonging to this cluster two three
of them belonging to this third cluster
okay so how do you decide that's exactly
the reason we should as much as possible
try to assign an odd number so that it
becomes easier to assign this so in this
case you see that the majority actually
if there are multiple classes then you
go with the majority so since three of
these items belong to this class we
assign which is basically the in in this
case the green or the tennis or the
third cluster as I was talking
right so we assign it to this third
class so in this case it is uh that's
how it is decided okay so K nearest
neighbor so first thing is to identify
the number of neighbors that are
mentioned as K so in this case it is K
is equal to 5 so we find the five
nearest points and then find out out of
these five which class has the maximum
number in that and and then the new data
point is assigned to that class okay and
with that we have come to end of this AI
crash course I hope you found it
valuable and entertaining please ask any
question about the topics covered in
this video in the comment section below
our expert will assist you in addressing
your problem thank you for watching stay
safe and keep learning by simply
learning staying ahead in your career
requires continuous learning and
upskilling whether you're a student
aiming to learn today's top skills or a
working professional looking to advance
your career we've got you covered
explore our impressive catalog of
certification programs in Cutting Edge
domains including data science cloud
computing cyber security AI machine
learning or digital marketing designed
in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to Career Success click the link in
the description to know more
hi there if you like this video
subscribe to the simply learned YouTube
channel and click here to watch similar
videos turn it up and get certified
click here